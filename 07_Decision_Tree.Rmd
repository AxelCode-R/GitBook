---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Decision Tree
The Decision Trees and Neuronal Netwoks aim for the same goal, analyzing the data and giving answers to never seen data. Nevertheless do they have huge differences in working with each of these methods. For this reason do i link [here](https://www.kdnuggets.com/2019/06/random-forest-vs-neural-network.html) an very good comparison of these two methods. The result is that Decision Trees are much simpler than Neuronal Networks with the additional fact that its easier to interpret the way of giving a certain answer. In comparison to this, can Neuronal Networks process very huge datasets with ease and you can adjust the behavior of learning strongly by the selected hyper-parameter, which can lead to very high accuracy. If you take all in consideration, its useful to think about Decision Trees, before you create a Neuronal Network, because its a simpler approach. If your data is more complex or large you should definitely go with the Neuronal Networks. In very complex situation they often will use hybrids of Decision Trees and Neuronal Networks to archive understandable results with high accuracy (for example [Neural-Backed Decision Trees](https://bair.berkeley.edu/blog/2020/04/23/decisions/)).  

## Entropy
Entropy measures the impurity of the given data. Low impurity leads to better classification and higher accuracy. The goal of Decision Trees is to split the data at each node with the highest gain of purity. The purity of the given dataset can be calculated with the Entropy-Formula:
$$
  E = -p \cdot log_2(p) - (1-p) \cdot log_2(1-p) 
$$

with $p$ as the probability of having no default in the credit default dataset. The Entropy increases to 1 if the dataset contains 50% of defaults and 50% of no default and decreases to 0 if the dataset contains only defaults or only no defaults. The python function is the following:
```{python}
def calc_entropy(df, decision_on = "loan_status"):
  if len(df)==0:
    return(0)
  p = np.sum(df[decision_on] == 0)/len(df)
  if p == 0 or p == 1:
    return(0)
  result = -p * ma.log(p,2) - (1-p)*ma.log(1-p,2)
  return result
```

Now can we calculate the initial Entropy of the credit default dataset as shown in the next code snippet:
```{python}
import numpy as np
import math as ma
import pandas as pd

data = pd.read_csv("example_data/credit_risk_dataset.csv").fillna(0)
data = data.replace({"Y": 1, "N":0})

entropy_of_data = calc_entropy(df=data)
print("Initial Inpurity/Entropy of data: ", entropy_of_data)
```

Sadly do we have the same problem with categorical data as the NN. We could transform categorical data to numerical as shown in the Credit Default chapter, but i want to drop these columns to make it easier to understand. Additional will we select only 4 columns plus the answer, to make it more interpretable and manageable.
```{python}
data = data.loc[:, ["person_age", "loan_percent_income", "loan_int_rate", "cb_person_default_on_file" ,"loan_status"]]
```

Now do we need to create the nodes of the tree based on decisions that lead to the lowest Entropy. The resulting purity by splitting the data in 2 subsets by a condition of one column (value $z$), can be calculated as:
$$
  p_1(z) = \text{proportion of column-value} > z \\
  p_2(z) = \text{proportion of no default and column-value} > z \\
  p_3(z) = \text{proportion of no default and column-value} \leq z \\
  E_{split} = p_1(z) \cdot [-p_2(z) \cdot log_2(p_2(z)) - (1-p_2(z)) \cdot log_2(1-p_2(z))] \\
  +(1-p_1(z)) \cdot [-p_3(z) \cdot log_2(p_3(z)) - (1-p_3(z)) \cdot log_2(1-p_3(z))]
$$

and in python can we use the `calc_entropy` function to make it even simpler:
```{python}
def calc_splitted_entropy(df, col, val, decision_on = "loan_status"):
  w = np.sum(df[col] > val)/len(df)
  result = w * calc_entropy(df.loc[df[col] > val], decision_on) + (1-w) * calc_entropy(df.loc[df[col] <= val], decision_on)
  return result
```

For example can we split the dataset by column `loan_percent_income` and value $z=0.3$ to archive an decrease in Entropy:
```{python}
entropy_of_splitted_data = calc_splitted_entropy(df=data, col="loan_percent_income", val=0.3, decision_on = "loan_status")
print("Splitted Inpurity/Entropy of data: ", entropy_of_splitted_data)
```
This split results in a decrease of `r round(entropy_of_data-entropy_of_splitted_data,5)` in the overall Entropy.  

## Constructing the Tree




```{python}
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as pyplot
import math as ma


data = pd.read_csv("example_data/credit_risk_dataset.csv").fillna(0)
data = data.replace({"Y": 1, "N":0})
data = data.loc[:, ["person_age", "loan_percent_income", "loan_int_rate", "cb_person_default_on_file" ,"loan_status"]]



def calc_entropy(df, decision_on = "loan_status"):
  if len(df)==0:
    return(0)
  p = np.sum(df[decision_on] == 0)/len(df)
  if p == 0 or p == 1:
    return(0)
  result = -p * ma.log(p,2) - (1-p)*ma.log(1-p,2)
  return result

def calc_splitted_entropy(df, col, val, decision_on = "loan_status"):
  w = np.sum(df[col] > val)/len(df)
  result = w * calc_entropy(df.loc[df[col] > val], decision_on) + (1-w) * calc_entropy(df.loc[df[col] <= val], decision_on)
  return result

def find_minima(df, col, decision_on = "loan_status", round_at = 5):
  direction = 1
  step = (df[col].max()-df[col].min()) * 0.1
  val = df[col].min() + step
  best_entropy = 1
  stagnation = 0
  
  while stagnation <= 15:
    temp = calc_splitted_entropy(df, col, val)
    if temp > best_entropy:
      direction = -direction
      step = 0.5 * step
      stagnation += 1
    elif round(temp,round_at) < round(best_entropy,round_at):
      stagnation = 0
    else:
      stagnation += 1
    best_entropy = temp
    val = val + direction * step
    
  return best_entropy, val


def find_best_col(df, decision_on = "loan_status", round_at = 5):
  cols = list(df.columns[df.columns != decision_on])
  entropys = np.ones(len(cols))
  vals = np.ones(len(cols))
  
  for i in range(len(cols)):
    entropys[i], vals[i] = find_minima(df, col=cols[i], decision_on = "loan_status", round_at = 5)
  
  best_i = int(np.where(entropys == min(entropys))[0][0])
  return cols[best_i], entropys[best_i], vals[best_i]




def make_node_and_leafs(df, decision_on = "loan_status", round_at = 5, path = "I", condition = "", min_size = 1000, max_depth = 4, leafs = pd.DataFrame(columns=["path", "condition", "rows", "P_of_no_default", "entropy"])):
  if len(df) < min_size or (path.count("-")-1) >= max_depth or len(df.columns) <= 1:
    leafs = leafs.append({"path":path+"}", "condition":condition[0:(len(condition)-5)], "rows":len(df), "P_of_no_default":np.sum(df[decision_on] == 0)/len(df), "entropy":calc_entropy(df)}, ignore_index=True)
  else:
    col, entropy, val = find_best_col(df, decision_on, round_at)
    print("path:", path, "   entropy:", entropy, "  col:", col, "   val:", val, "  rows:", len(df))
    leafs = make_node_and_leafs( df.loc[df[col] > val, df.columns != col], decision_on, round_at, path+"-R", condition+col+" > "+str(float(round(val,5)))+" and ", min_size, max_depth, leafs)
    leafs = make_node_and_leafs( df.loc[df[col] <= val, df.columns != col], decision_on, round_at, path + "-L", condition+col+" <= "+str(float(round(val,5)))+" and ", min_size, max_depth, leafs)
  return(leafs)
  
  
  


leafs = make_node_and_leafs(df=data, decision_on = "loan_status", round_at = 5, min_size = 1000, max_depth = 4)
leafs["entropy"] = (leafs["entropy"]*leafs["rows"])/len(data)

print("Entropy in data: ", calc_entropy(data))
print("Entropy in all leafs: ", np.sum(leafs["entropy"]))


data_temp = data.copy()
data_temp["ID"] = list(range(len(data_temp)))
conditions = "("+ ") | (".join(list(leafs.loc[leafs["P_of_no_default"] < 0.65, leafs.columns == "condition"]["condition"].replace("and","&")))+")"
data_temp = data_temp.query(conditions)
X = np.zeros(len(data))
X[list(data_temp["ID"])] = 1

Y = data.loc[:, data.columns == 'loan_status'].to_numpy()[:,0]

print("Wrong answers of the decission tree: ",np.sum(np.abs(Y-X))/len(Y) * 100, "%")
confusion_matrix(Y,X)





from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz, export_text
X = data.drop('loan_status',axis=1)
y = data['loan_status']
clf = DecisionTreeClassifier(criterion='entropy',max_depth=4,min_samples_split=1000,min_samples_leaf=200,random_state=0)
clf = clf.fit(X,y)
pyplot.figure(figsize=(16,8))
plot_tree(clf, filled=True, feature_names=X.columns, proportion=False, fontsize=6)
pyplot.show()

r = export_text(clf, feature_names=list(X.columns))
print(r)

#(13179*0.334+8257*0.502+488*0.878+2075*0.619+706*0.83+1542*0.974+1746*0.995+754*0.995+767*0.98+628*0.924+227*0.8+1000*0.9)/len(data)
```





