<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Class MLP | gitbook-demo.knit</title>
  <meta name="description" content="This GitBook should provide an slide insight into my own learning process of coding Neuronal Networks (NN). Additionaly its a good chance for me to learn how to write a GitBook." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Class MLP | gitbook-demo.knit" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This GitBook should provide an slide insight into my own learning process of coding Neuronal Networks (NN). Additionaly its a good chance for me to learn how to write a GitBook." />
  <meta name="github-repo" content="https://github.com/AxelCode-R/GitBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Class MLP | gitbook-demo.knit" />
  
  <meta name="twitter:description" content="This GitBook should provide an slide insight into my own learning process of coding Neuronal Networks (NN). Additionaly its a good chance for me to learn how to write a GitBook." />
  

<meta name="author" content="Axel Roth" />


<meta name="date" content="2021-11-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="effect-of-batch-size.html"/>
<link rel="next" href="decision-tree.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A GitBook</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#me"><i class="fa fa-check"></i><b>1.1</b> Me</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#the-book"><i class="fa fa-check"></i><b>1.2</b> The Book</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#how-it-works"><i class="fa fa-check"></i><b>1.3</b> How it works</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="single-perceptron.html"><a href="single-perceptron.html"><i class="fa fa-check"></i><b>2</b> Single Perceptron</a>
<ul>
<li class="chapter" data-level="2.1" data-path="single-perceptron.html"><a href="single-perceptron.html#neural-network-basics"><i class="fa fa-check"></i><b>2.1</b> Neural Network Basics</a></li>
<li class="chapter" data-level="2.2" data-path="single-perceptron.html"><a href="single-perceptron.html#forward-pass"><i class="fa fa-check"></i><b>2.2</b> Forward pass</a></li>
<li class="chapter" data-level="2.3" data-path="single-perceptron.html"><a href="single-perceptron.html#backward-pass"><i class="fa fa-check"></i><b>2.3</b> Backward pass</a></li>
<li class="chapter" data-level="2.4" data-path="single-perceptron.html"><a href="single-perceptron.html#single-perceptron-1"><i class="fa fa-check"></i><b>2.4</b> Single Perceptron</a></li>
<li class="chapter" data-level="2.5" data-path="single-perceptron.html"><a href="single-perceptron.html#why-does-it-work"><i class="fa fa-check"></i><b>2.5</b> Why does it work?</a></li>
<li class="chapter" data-level="2.6" data-path="single-perceptron.html"><a href="single-perceptron.html#appendix-complete-code"><i class="fa fa-check"></i><b>2.6</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="adding-trainable-bias.html"><a href="adding-trainable-bias.html"><i class="fa fa-check"></i><b>3</b> Adding trainable Bias</a>
<ul>
<li class="chapter" data-level="3.1" data-path="adding-trainable-bias.html"><a href="adding-trainable-bias.html#generalising-the-bias"><i class="fa fa-check"></i><b>3.1</b> Generalising the Bias</a></li>
<li class="chapter" data-level="3.2" data-path="adding-trainable-bias.html"><a href="adding-trainable-bias.html#appendix-complete-code-1"><i class="fa fa-check"></i><b>3.2</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multilayer-perceptrons-mlp.html"><a href="multilayer-perceptrons-mlp.html"><i class="fa fa-check"></i><b>4</b> Multilayer Perceptrons (MLP)</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multilayer-perceptrons-mlp.html"><a href="multilayer-perceptrons-mlp.html#forward-pass-1"><i class="fa fa-check"></i><b>4.1</b> Forward pass</a></li>
<li class="chapter" data-level="4.2" data-path="multilayer-perceptrons-mlp.html"><a href="multilayer-perceptrons-mlp.html#backward-pass-1"><i class="fa fa-check"></i><b>4.2</b> Backward pass</a></li>
<li class="chapter" data-level="4.3" data-path="multilayer-perceptrons-mlp.html"><a href="multilayer-perceptrons-mlp.html#appendix-complete-code-2"><i class="fa fa-check"></i><b>4.3</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mlp-example-credit-default.html"><a href="mlp-example-credit-default.html"><i class="fa fa-check"></i><b>5</b> MLP example (Credit Default)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="mlp-example-credit-default.html"><a href="mlp-example-credit-default.html#loading-and-analysing-the-data"><i class="fa fa-check"></i><b>5.1</b> Loading and analysing the data</a></li>
<li class="chapter" data-level="5.2" data-path="mlp-example-credit-default.html"><a href="mlp-example-credit-default.html#train-and-test-phase"><i class="fa fa-check"></i><b>5.2</b> Train and test phase</a></li>
<li class="chapter" data-level="5.3" data-path="mlp-example-credit-default.html"><a href="mlp-example-credit-default.html#appendix-complete-code-3"><i class="fa fa-check"></i><b>5.3</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="effect-of-batch-size.html"><a href="effect-of-batch-size.html"><i class="fa fa-check"></i><b>6</b> Effect of batch size</a>
<ul>
<li class="chapter" data-level="6.1" data-path="effect-of-batch-size.html"><a href="effect-of-batch-size.html#impact-of-diffrent-hyperparameters"><i class="fa fa-check"></i><b>6.1</b> Impact of diffrent hyperparameters</a></li>
<li class="chapter" data-level="6.2" data-path="effect-of-batch-size.html"><a href="effect-of-batch-size.html#appendix-complete-code-4"><i class="fa fa-check"></i><b>6.2</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="class-mlp.html"><a href="class-mlp.html"><i class="fa fa-check"></i><b>7</b> Class MLP</a></li>
<li class="chapter" data-level="8" data-path="decision-tree.html"><a href="decision-tree.html"><i class="fa fa-check"></i><b>8</b> Decision Tree</a>
<ul>
<li class="chapter" data-level="8.1" data-path="decision-tree.html"><a href="decision-tree.html#entropy"><i class="fa fa-check"></i><b>8.1</b> Entropy</a></li>
<li class="chapter" data-level="8.2" data-path="decision-tree.html"><a href="decision-tree.html#constructing-the-tree"><i class="fa fa-check"></i><b>8.2</b> Constructing the Tree</a></li>
<li class="chapter" data-level="8.3" data-path="decision-tree.html"><a href="decision-tree.html#forcast-credit-defaults-with-dt"><i class="fa fa-check"></i><b>8.3</b> Forcast Credit Defaults with DT</a></li>
<li class="chapter" data-level="8.4" data-path="decision-tree.html"><a href="decision-tree.html#extern-packages"><i class="fa fa-check"></i><b>8.4</b> Extern Packages</a></li>
<li class="chapter" data-level="8.5" data-path="decision-tree.html"><a href="decision-tree.html#appendix-complete-code-5"><i class="fa fa-check"></i><b>8.5</b> Appendix (complete code)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><div class="line-block">My First Steps in Neuronal Networks<br />
(Beginners Guide)</div></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="class-mlp" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Class MLP</h1>
<p>Finally, can we create a ‘MLP’ class that contains all of the functions from the preview chapters. You can use this class to play around with different settings and learn new things about the datasets you’ve chosen.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="class-mlp.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb61-2"><a href="class-mlp.html#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> pyplot</span>
<span id="cb61-3"><a href="class-mlp.html#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb61-4"><a href="class-mlp.html#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb61-5"><a href="class-mlp.html#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math <span class="im">as</span> ma</span>
<span id="cb61-6"><a href="class-mlp.html#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb61-7"><a href="class-mlp.html#cb61-7" aria-hidden="true" tabindex="-1"></a>np.warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>, category<span class="op">=</span>np.VisibleDeprecationWarning) </span>
<span id="cb61-8"><a href="class-mlp.html#cb61-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-9"><a href="class-mlp.html#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP:</span>
<span id="cb61-10"><a href="class-mlp.html#cb61-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X_train, Y_train, X_test, Y_test, hidden_layer_neurons, alpha, epochs, batch_size):</span>
<span id="cb61-11"><a href="class-mlp.html#cb61-11" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.X_train <span class="op">=</span> X_train</span>
<span id="cb61-12"><a href="class-mlp.html#cb61-12" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.Y_train <span class="op">=</span> Y_train</span>
<span id="cb61-13"><a href="class-mlp.html#cb61-13" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.X_test <span class="op">=</span> X_test</span>
<span id="cb61-14"><a href="class-mlp.html#cb61-14" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.Y_test <span class="op">=</span> Y_test</span>
<span id="cb61-15"><a href="class-mlp.html#cb61-15" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.hidden_layer_neurons <span class="op">=</span> hidden_layer_neurons</span>
<span id="cb61-16"><a href="class-mlp.html#cb61-16" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.alpha <span class="op">=</span> alpha</span>
<span id="cb61-17"><a href="class-mlp.html#cb61-17" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.epochs <span class="op">=</span> epochs</span>
<span id="cb61-18"><a href="class-mlp.html#cb61-18" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.batch_size <span class="op">=</span> batch_size</span>
<span id="cb61-19"><a href="class-mlp.html#cb61-19" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb61-20"><a href="class-mlp.html#cb61-20" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> generate_weights(<span class="va">self</span>):</span>
<span id="cb61-21"><a href="class-mlp.html#cb61-21" aria-hidden="true" tabindex="-1"></a>    W <span class="op">=</span> []</span>
<span id="cb61-22"><a href="class-mlp.html#cb61-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>.hidden_layer_neurons)<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb61-23"><a href="class-mlp.html#cb61-23" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> i <span class="op">==</span> <span class="dv">0</span>: <span class="co"># first layer</span></span>
<span id="cb61-24"><a href="class-mlp.html#cb61-24" aria-hidden="true" tabindex="-1"></a>        W.append(np.random.random((<span class="bu">len</span>(<span class="va">self</span>.X_train)<span class="op">+</span><span class="dv">1</span>, <span class="va">self</span>.hidden_layer_neurons[i])))</span>
<span id="cb61-25"><a href="class-mlp.html#cb61-25" aria-hidden="true" tabindex="-1"></a>      <span class="cf">elif</span> i <span class="op">==</span> <span class="bu">len</span>(<span class="va">self</span>.hidden_layer_neurons): <span class="co"># last layer</span></span>
<span id="cb61-26"><a href="class-mlp.html#cb61-26" aria-hidden="true" tabindex="-1"></a>        W.append(np.random.random((<span class="va">self</span>.hidden_layer_neurons[i<span class="op">-</span><span class="dv">1</span>]<span class="op">+</span><span class="dv">1</span>, <span class="bu">len</span>(<span class="va">self</span>.Y_train))))</span>
<span id="cb61-27"><a href="class-mlp.html#cb61-27" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>: <span class="co"># middle layers</span></span>
<span id="cb61-28"><a href="class-mlp.html#cb61-28" aria-hidden="true" tabindex="-1"></a>        W.append(np.random.random((<span class="va">self</span>.hidden_layer_neurons[i<span class="op">-</span><span class="dv">1</span>]<span class="op">+</span><span class="dv">1</span>, <span class="va">self</span>.hidden_layer_neurons[i])))</span>
<span id="cb61-29"><a href="class-mlp.html#cb61-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(W)</span>
<span id="cb61-30"><a href="class-mlp.html#cb61-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-31"><a href="class-mlp.html#cb61-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">@staticmethod</span></span>
<span id="cb61-32"><a href="class-mlp.html#cb61-32" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> add_ones_to_input(x):</span>
<span id="cb61-33"><a href="class-mlp.html#cb61-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(np.append(x, np.array([np.ones(<span class="bu">len</span>(x))]).T, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb61-34"><a href="class-mlp.html#cb61-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">@staticmethod</span></span>
<span id="cb61-35"><a href="class-mlp.html#cb61-35" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> sigmoid(x):</span>
<span id="cb61-36"><a href="class-mlp.html#cb61-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fl">1.0</span> <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">+</span> np.exp(<span class="op">-</span>x))</span>
<span id="cb61-37"><a href="class-mlp.html#cb61-37" aria-hidden="true" tabindex="-1"></a>  <span class="at">@staticmethod</span></span>
<span id="cb61-38"><a href="class-mlp.html#cb61-38" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> deriv_sigmoid(x):</span>
<span id="cb61-39"><a href="class-mlp.html#cb61-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> x)</span>
<span id="cb61-40"><a href="class-mlp.html#cb61-40" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb61-41"><a href="class-mlp.html#cb61-41" aria-hidden="true" tabindex="-1"></a>  <span class="at">@staticmethod</span></span>
<span id="cb61-42"><a href="class-mlp.html#cb61-42" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(x, w):</span>
<span id="cb61-43"><a href="class-mlp.html#cb61-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>( sigmoid(x <span class="op">@</span> w) )</span>
<span id="cb61-44"><a href="class-mlp.html#cb61-44" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb61-45"><a href="class-mlp.html#cb61-45" aria-hidden="true" tabindex="-1"></a>  <span class="at">@staticmethod</span></span>
<span id="cb61-46"><a href="class-mlp.html#cb61-46" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> backward(IN, OUT, W, Y, grad, k):</span>
<span id="cb61-47"><a href="class-mlp.html#cb61-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> k <span class="op">==</span> <span class="bu">len</span>(grad)<span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb61-48"><a href="class-mlp.html#cb61-48" aria-hidden="true" tabindex="-1"></a>      grad[k] <span class="op">=</span> deriv_sigmoid(OUT[k]) <span class="op">*</span> (Y<span class="op">-</span>OUT[k])</span>
<span id="cb61-49"><a href="class-mlp.html#cb61-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb61-50"><a href="class-mlp.html#cb61-50" aria-hidden="true" tabindex="-1"></a>      grad[k] <span class="op">=</span> deriv_sigmoid(OUT[k]) <span class="op">*</span>(grad[k<span class="op">+</span><span class="dv">1</span>] <span class="op">@</span> W[k<span class="op">+</span><span class="dv">1</span>][<span class="dv">0</span>:<span class="bu">len</span>(W[k<span class="op">+</span><span class="dv">1</span>])<span class="op">-</span><span class="dv">1</span>].T)</span>
<span id="cb61-51"><a href="class-mlp.html#cb61-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(grad)</span>
<span id="cb61-52"><a href="class-mlp.html#cb61-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-53"><a href="class-mlp.html#cb61-53" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> generate_random_batches(<span class="va">self</span>):</span>
<span id="cb61-54"><a href="class-mlp.html#cb61-54" aria-hidden="true" tabindex="-1"></a>    batches <span class="op">=</span> np.arange(<span class="bu">len</span>(<span class="va">self</span>.X_train))</span>
<span id="cb61-55"><a href="class-mlp.html#cb61-55" aria-hidden="true" tabindex="-1"></a>    np.random.shuffle(batches)</span>
<span id="cb61-56"><a href="class-mlp.html#cb61-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(np.array_split(batches, ma.ceil(<span class="bu">len</span>(<span class="va">self</span>.X_train)<span class="op">/</span><span class="va">self</span>.batch_size)))</span>
<span id="cb61-57"><a href="class-mlp.html#cb61-57" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-58"><a href="class-mlp.html#cb61-58" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> train(<span class="va">self</span>):</span>
<span id="cb61-59"><a href="class-mlp.html#cb61-59" aria-hidden="true" tabindex="-1"></a>    W <span class="op">=</span> <span class="va">self</span>.generate_weights()</span>
<span id="cb61-60"><a href="class-mlp.html#cb61-60" aria-hidden="true" tabindex="-1"></a>    errors <span class="op">=</span> []</span>
<span id="cb61-61"><a href="class-mlp.html#cb61-61" aria-hidden="true" tabindex="-1"></a>    batches <span class="op">=</span> <span class="va">self</span>.generate_random_batches()</span>
<span id="cb61-62"><a href="class-mlp.html#cb61-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.epochs):</span>
<span id="cb61-63"><a href="class-mlp.html#cb61-63" aria-hidden="true" tabindex="-1"></a>      error_temp <span class="op">=</span> np.array([])</span>
<span id="cb61-64"><a href="class-mlp.html#cb61-64" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> z <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(batches)):</span>
<span id="cb61-65"><a href="class-mlp.html#cb61-65" aria-hidden="true" tabindex="-1"></a>        IN <span class="op">=</span> []</span>
<span id="cb61-66"><a href="class-mlp.html#cb61-66" aria-hidden="true" tabindex="-1"></a>        OUT <span class="op">=</span> []</span>
<span id="cb61-67"><a href="class-mlp.html#cb61-67" aria-hidden="true" tabindex="-1"></a>        grad <span class="op">=</span> [<span class="va">None</span>]<span class="op">*</span><span class="bu">len</span>(W)</span>
<span id="cb61-68"><a href="class-mlp.html#cb61-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(W)):</span>
<span id="cb61-69"><a href="class-mlp.html#cb61-69" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> k<span class="op">==</span><span class="dv">0</span>:</span>
<span id="cb61-70"><a href="class-mlp.html#cb61-70" aria-hidden="true" tabindex="-1"></a>            IN.append(<span class="va">self</span>.add_ones_to_input(x <span class="op">=</span> <span class="va">self</span>.X_train[batches[z],:]))</span>
<span id="cb61-71"><a href="class-mlp.html#cb61-71" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span>:</span>
<span id="cb61-72"><a href="class-mlp.html#cb61-72" aria-hidden="true" tabindex="-1"></a>            IN.append(<span class="va">self</span>.add_ones_to_input(x <span class="op">=</span> OUT[k<span class="op">-</span><span class="dv">1</span>]))</span>
<span id="cb61-73"><a href="class-mlp.html#cb61-73" aria-hidden="true" tabindex="-1"></a>          OUT.append(<span class="va">self</span>.forward(IN[k], W[k]))</span>
<span id="cb61-74"><a href="class-mlp.html#cb61-74" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb61-75"><a href="class-mlp.html#cb61-75" aria-hidden="true" tabindex="-1"></a>        error_temp <span class="op">=</span> np.append(error_temp, <span class="va">self</span>.Y_train[batches[z],:] <span class="op">-</span> OUT[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb61-76"><a href="class-mlp.html#cb61-76" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb61-77"><a href="class-mlp.html#cb61-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(W)<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb61-78"><a href="class-mlp.html#cb61-78" aria-hidden="true" tabindex="-1"></a>          grad <span class="op">=</span> <span class="va">self</span>.backward(IN, OUT, W, <span class="va">self</span>.Y_train[batches[z],:], grad, k) </span>
<span id="cb61-79"><a href="class-mlp.html#cb61-79" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb61-80"><a href="class-mlp.html#cb61-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(W)):</span>
<span id="cb61-81"><a href="class-mlp.html#cb61-81" aria-hidden="true" tabindex="-1"></a>          W[k] <span class="op">=</span> W[k] <span class="op">+</span> <span class="va">self</span>.alpha <span class="op">*</span> (IN[k].T <span class="op">@</span> grad[k])</span>
<span id="cb61-82"><a href="class-mlp.html#cb61-82" aria-hidden="true" tabindex="-1"></a>      errors.append(error_temp)</span>
<span id="cb61-83"><a href="class-mlp.html#cb61-83" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.W <span class="op">=</span> W</span>
<span id="cb61-84"><a href="class-mlp.html#cb61-84" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.errors <span class="op">=</span> errors</span>
<span id="cb61-85"><a href="class-mlp.html#cb61-85" aria-hidden="true" tabindex="-1"></a>  <span class="at">@staticmethod</span></span>
<span id="cb61-86"><a href="class-mlp.html#cb61-86" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> mean_square_error(error):</span>
<span id="cb61-87"><a href="class-mlp.html#cb61-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>( <span class="fl">0.5</span> <span class="op">*</span> np.<span class="bu">sum</span>(error <span class="op">**</span> <span class="dv">2</span>) )</span>
<span id="cb61-88"><a href="class-mlp.html#cb61-88" aria-hidden="true" tabindex="-1"></a>  <span class="at">@staticmethod</span></span>
<span id="cb61-89"><a href="class-mlp.html#cb61-89" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> plot_error(errors, title):</span>
<span id="cb61-90"><a href="class-mlp.html#cb61-90" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(errors)))</span>
<span id="cb61-91"><a href="class-mlp.html#cb61-91" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.array(errors)</span>
<span id="cb61-92"><a href="class-mlp.html#cb61-92" aria-hidden="true" tabindex="-1"></a>    pyplot.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">6</span>))</span>
<span id="cb61-93"><a href="class-mlp.html#cb61-93" aria-hidden="true" tabindex="-1"></a>    pyplot.plot(x, y, <span class="st">&quot;g&quot;</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb61-94"><a href="class-mlp.html#cb61-94" aria-hidden="true" tabindex="-1"></a>    pyplot.xlabel(<span class="st">&quot;Iterations&quot;</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb61-95"><a href="class-mlp.html#cb61-95" aria-hidden="true" tabindex="-1"></a>    pyplot.ylabel(<span class="st">&quot;Mean Square Error&quot;</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb61-96"><a href="class-mlp.html#cb61-96" aria-hidden="true" tabindex="-1"></a>    pyplot.title(title)</span>
<span id="cb61-97"><a href="class-mlp.html#cb61-97" aria-hidden="true" tabindex="-1"></a>    pyplot.ylim(<span class="dv">0</span>,<span class="bu">max</span>(errors)<span class="op">*</span><span class="fl">1.1</span>)</span>
<span id="cb61-98"><a href="class-mlp.html#cb61-98" aria-hidden="true" tabindex="-1"></a>    pyplot.show()</span>
<span id="cb61-99"><a href="class-mlp.html#cb61-99" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-100"><a href="class-mlp.html#cb61-100" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> test(<span class="va">self</span>):</span>
<span id="cb61-101"><a href="class-mlp.html#cb61-101" aria-hidden="true" tabindex="-1"></a>    X_test <span class="op">=</span> <span class="va">self</span>.X_test</span>
<span id="cb61-102"><a href="class-mlp.html#cb61-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>.W)):</span>
<span id="cb61-103"><a href="class-mlp.html#cb61-103" aria-hidden="true" tabindex="-1"></a>      X_test <span class="op">=</span> <span class="va">self</span>.forward(<span class="va">self</span>.add_ones_to_input(X_test), <span class="va">self</span>.W[i])</span>
<span id="cb61-104"><a href="class-mlp.html#cb61-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(X_test)</span>
<span id="cb61-105"><a href="class-mlp.html#cb61-105" aria-hidden="true" tabindex="-1"></a>  <span class="at">@staticmethod</span></span>
<span id="cb61-106"><a href="class-mlp.html#cb61-106" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> classify(Y_approx):</span>
<span id="cb61-107"><a href="class-mlp.html#cb61-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>( np.<span class="bu">round</span>(Y_approx,<span class="dv">0</span>) )</span></code></pre></div>
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="class-mlp.html#cb62-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&quot;example_data/credit_risk_dataset.csv&quot;</span>).fillna(<span class="dv">0</span>)</span>
<span id="cb62-2"><a href="class-mlp.html#cb62-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.replace({<span class="st">&quot;Y&quot;</span>: <span class="dv">1</span>, <span class="st">&quot;N&quot;</span>:<span class="dv">0</span>})</span>
<span id="cb62-3"><a href="class-mlp.html#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="class-mlp.html#cb62-4" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&quot;person_home_ownership&quot;</span>] <span class="op">=</span> data[<span class="st">&quot;person_home_ownership&quot;</span>].replace({<span class="st">&#39;OWN&#39;</span>:<span class="dv">1</span>, <span class="st">&#39;RENT&#39;</span>:<span class="dv">2</span>, <span class="st">&#39;MORTGAGE&#39;</span>:<span class="dv">3</span>, <span class="st">&#39;OTHER&#39;</span>:<span class="dv">4</span>})</span>
<span id="cb62-5"><a href="class-mlp.html#cb62-5" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&quot;loan_intent&quot;</span>] <span class="op">=</span> data[<span class="st">&quot;loan_intent&quot;</span>].replace({<span class="st">&#39;PERSONAL&#39;</span>:<span class="dv">1</span>, <span class="st">&#39;EDUCATION&#39;</span>:<span class="dv">2</span>, <span class="st">&#39;MEDICAL&#39;</span>:<span class="dv">3</span>, <span class="st">&#39;VENTURE&#39;</span>:<span class="dv">4</span>, <span class="st">&#39;HOMEIMPROVEMENT&#39;</span>:<span class="dv">5</span>,<span class="st">&#39;DEBTCONSOLIDATION&#39;</span>:<span class="dv">6</span>})</span>
<span id="cb62-6"><a href="class-mlp.html#cb62-6" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&quot;loan_grade&quot;</span>] <span class="op">=</span> data[<span class="st">&quot;loan_grade&quot;</span>].replace({<span class="st">&#39;A&#39;</span>:<span class="dv">1</span>, <span class="st">&#39;B&#39;</span>:<span class="dv">2</span>, <span class="st">&#39;C&#39;</span>:<span class="dv">3</span>, <span class="st">&#39;D&#39;</span>:<span class="dv">4</span>, <span class="st">&#39;E&#39;</span>:<span class="dv">5</span>, <span class="st">&#39;F&#39;</span>:<span class="dv">6</span>, <span class="st">&#39;G&#39;</span>:<span class="dv">7</span>})</span>
<span id="cb62-7"><a href="class-mlp.html#cb62-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-8"><a href="class-mlp.html#cb62-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> NormalizeData(np_arr):</span>
<span id="cb62-9"><a href="class-mlp.html#cb62-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(np_arr.shape[<span class="dv">1</span>]):</span>
<span id="cb62-10"><a href="class-mlp.html#cb62-10" aria-hidden="true" tabindex="-1"></a>    np_arr[:,i] <span class="op">=</span> (np_arr[:,i] <span class="op">-</span> np.<span class="bu">min</span>(np_arr[:,i])) <span class="op">/</span> (np.<span class="bu">max</span>(np_arr[:,i]) <span class="op">-</span> np.<span class="bu">min</span>(np_arr[:,i]))</span>
<span id="cb62-11"><a href="class-mlp.html#cb62-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(np_arr)</span>
<span id="cb62-12"><a href="class-mlp.html#cb62-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-13"><a href="class-mlp.html#cb62-13" aria-hidden="true" tabindex="-1"></a>training_n <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb62-14"><a href="class-mlp.html#cb62-14" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> NormalizeData( data.loc[<span class="dv">0</span>:(training_n<span class="op">-</span><span class="dv">1</span>), data.columns <span class="op">!=</span> <span class="st">&#39;loan_status&#39;</span>].to_numpy() )</span>
<span id="cb62-15"><a href="class-mlp.html#cb62-15" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> data.loc[<span class="dv">0</span>:(training_n<span class="op">-</span><span class="dv">1</span>), data.columns <span class="op">==</span> <span class="st">&#39;loan_status&#39;</span>].to_numpy()</span>
<span id="cb62-16"><a href="class-mlp.html#cb62-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-17"><a href="class-mlp.html#cb62-17" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> NormalizeData( data.loc[training_n:, data.columns <span class="op">!=</span> <span class="st">&#39;loan_status&#39;</span>].to_numpy() )</span>
<span id="cb62-18"><a href="class-mlp.html#cb62-18" aria-hidden="true" tabindex="-1"></a>Y_test <span class="op">=</span> data.loc[training_n:, data.columns <span class="op">==</span> <span class="st">&#39;loan_status&#39;</span>].to_numpy()</span>
<span id="cb62-19"><a href="class-mlp.html#cb62-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-20"><a href="class-mlp.html#cb62-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-21"><a href="class-mlp.html#cb62-21" aria-hidden="true" tabindex="-1"></a><span class="co"># mlp = MLP(X_train, Y_train, X_test, Y_test, hidden_layer_neurons = [11,4], alpha = 0.01, epochs = 2000, batch_size = 2000)</span></span>
<span id="cb62-22"><a href="class-mlp.html#cb62-22" aria-hidden="true" tabindex="-1"></a><span class="co"># mlp.train()</span></span></code></pre></div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="effect-of-batch-size.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="decision-tree.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/AxelCode-R/GitBook/edit/master/06_Class_MLP.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["gitbook-demo.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
