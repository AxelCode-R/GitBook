<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Decision Tree | gitbook-demo.knit</title>
  <meta name="description" content="This GitBook should provide an slide insight into my own learning process of coding Neuronal Networks (NN). Additionaly its a good chance for me to learn how to write a GitBook." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Decision Tree | gitbook-demo.knit" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This GitBook should provide an slide insight into my own learning process of coding Neuronal Networks (NN). Additionaly its a good chance for me to learn how to write a GitBook." />
  <meta name="github-repo" content="https://github.com/AxelCode-R/GitBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Decision Tree | gitbook-demo.knit" />
  
  <meta name="twitter:description" content="This GitBook should provide an slide insight into my own learning process of coding Neuronal Networks (NN). Additionaly its a good chance for me to learn how to write a GitBook." />
  

<meta name="author" content="Axel Roth" />


<meta name="date" content="2021-11-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="class-mlp.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A GitBook for Teaching</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#me"><i class="fa fa-check"></i><b>1.1</b> Me</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#the-book"><i class="fa fa-check"></i><b>1.2</b> The Book</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#how-it-works"><i class="fa fa-check"></i><b>1.3</b> How it works</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="single-perceptron.html"><a href="single-perceptron.html"><i class="fa fa-check"></i><b>2</b> Single Perceptron</a>
<ul>
<li class="chapter" data-level="2.1" data-path="single-perceptron.html"><a href="single-perceptron.html#neural-network-basics"><i class="fa fa-check"></i><b>2.1</b> Neural Network Basics</a></li>
<li class="chapter" data-level="2.2" data-path="single-perceptron.html"><a href="single-perceptron.html#forward-pass"><i class="fa fa-check"></i><b>2.2</b> Forward pass</a></li>
<li class="chapter" data-level="2.3" data-path="single-perceptron.html"><a href="single-perceptron.html#backward-pass"><i class="fa fa-check"></i><b>2.3</b> Backward pass</a></li>
<li class="chapter" data-level="2.4" data-path="single-perceptron.html"><a href="single-perceptron.html#single-perceptron-1"><i class="fa fa-check"></i><b>2.4</b> Single Perceptron</a></li>
<li class="chapter" data-level="2.5" data-path="single-perceptron.html"><a href="single-perceptron.html#why-does-it-work"><i class="fa fa-check"></i><b>2.5</b> Why does it work?</a></li>
<li class="chapter" data-level="2.6" data-path="single-perceptron.html"><a href="single-perceptron.html#appendix-complete-code"><i class="fa fa-check"></i><b>2.6</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="adding-trainable-bias.html"><a href="adding-trainable-bias.html"><i class="fa fa-check"></i><b>3</b> Adding trainable Bias</a>
<ul>
<li class="chapter" data-level="3.1" data-path="adding-trainable-bias.html"><a href="adding-trainable-bias.html#generalising-the-bias"><i class="fa fa-check"></i><b>3.1</b> Generalising the Bias</a></li>
<li class="chapter" data-level="3.2" data-path="adding-trainable-bias.html"><a href="adding-trainable-bias.html#appendix-complete-code-1"><i class="fa fa-check"></i><b>3.2</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multi-layer-perceptrons-mlp.html"><a href="multi-layer-perceptrons-mlp.html"><i class="fa fa-check"></i><b>4</b> Multi Layer Perceptrons (MLP)</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multi-layer-perceptrons-mlp.html"><a href="multi-layer-perceptrons-mlp.html#forward-pass-1"><i class="fa fa-check"></i><b>4.1</b> Forward pass</a></li>
<li class="chapter" data-level="4.2" data-path="multi-layer-perceptrons-mlp.html"><a href="multi-layer-perceptrons-mlp.html#backward-pass-1"><i class="fa fa-check"></i><b>4.2</b> Backward pass</a></li>
<li class="chapter" data-level="4.3" data-path="multi-layer-perceptrons-mlp.html"><a href="multi-layer-perceptrons-mlp.html#appendix-complete-code-2"><i class="fa fa-check"></i><b>4.3</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mlp-example-credit-default.html"><a href="mlp-example-credit-default.html"><i class="fa fa-check"></i><b>5</b> MLP example (Credit Default)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="mlp-example-credit-default.html"><a href="mlp-example-credit-default.html#loading-and-analysing-the-data"><i class="fa fa-check"></i><b>5.1</b> Loading and analysing the data</a></li>
<li class="chapter" data-level="5.2" data-path="mlp-example-credit-default.html"><a href="mlp-example-credit-default.html#train-and-test-phase"><i class="fa fa-check"></i><b>5.2</b> Train and test phase</a></li>
<li class="chapter" data-level="5.3" data-path="mlp-example-credit-default.html"><a href="mlp-example-credit-default.html#appendix-complete-code-3"><i class="fa fa-check"></i><b>5.3</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="effect-of-batch-size.html"><a href="effect-of-batch-size.html"><i class="fa fa-check"></i><b>6</b> Effect of batch size</a>
<ul>
<li class="chapter" data-level="6.1" data-path="effect-of-batch-size.html"><a href="effect-of-batch-size.html#impact-of-diffrent-hyperparameters"><i class="fa fa-check"></i><b>6.1</b> Impact of diffrent hyperparameters</a></li>
<li class="chapter" data-level="6.2" data-path="effect-of-batch-size.html"><a href="effect-of-batch-size.html#appendix-complete-code-4"><i class="fa fa-check"></i><b>6.2</b> Appendix (complete code)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="class-mlp.html"><a href="class-mlp.html"><i class="fa fa-check"></i><b>7</b> Class MLP</a></li>
<li class="chapter" data-level="8" data-path="decision-tree.html"><a href="decision-tree.html"><i class="fa fa-check"></i><b>8</b> Decision Tree</a>
<ul>
<li class="chapter" data-level="8.1" data-path="decision-tree.html"><a href="decision-tree.html#entropy"><i class="fa fa-check"></i><b>8.1</b> Entropy</a></li>
<li class="chapter" data-level="8.2" data-path="decision-tree.html"><a href="decision-tree.html#constructing-the-tree"><i class="fa fa-check"></i><b>8.2</b> Constructing the Tree</a></li>
<li class="chapter" data-level="8.3" data-path="decision-tree.html"><a href="decision-tree.html#forcast-credit-defaults-with-dt"><i class="fa fa-check"></i><b>8.3</b> Forcast Credit Defaults with DT</a></li>
<li class="chapter" data-level="8.4" data-path="decision-tree.html"><a href="decision-tree.html#extern-packages"><i class="fa fa-check"></i><b>8.4</b> Extern Packages</a></li>
<li class="chapter" data-level="8.5" data-path="decision-tree.html"><a href="decision-tree.html#appendix-complete-code-5"><i class="fa fa-check"></i><b>8.5</b> Appendix (complete code)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><div class="line-block">My First Steps in Neuronal Networks<br />
(Beginners Guide)</div></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="decision-tree" class="section level1" number="8">
<h1><span class="header-section-number">Chapter 8</span> Decision Tree</h1>
<p>The Decision Trees (DT) and Neuronal Netwoks (NN) aim for the same goal, analyzing the data and giving answers to never seen data. Nevertheless do they have huge differences in working with each of these methods. For this reason do i link <a href="https://www.kdnuggets.com/2019/06/random-forest-vs-neural-network.html">here</a> an very good comparison of these two methods. The result is that Decision Trees are much simpler than Neuronal Networks with the additional fact that its easier to interpret the way of giving a certain answer. In comparison to this, can Neuronal Networks process very huge datasets with ease and you can adjust the behavior of learning strongly by the selected hyper-parameter, which can lead to very high accuracy. If you take all in consideration, its useful to think about Decision Trees, before you create a Neuronal Network, because its a simpler approach. If your data is more complex or large you should definitely go with the Neuronal Networks. In very complex situation they often will use hybrids of Decision Trees and Neuronal Networks to archive understandable results with high accuracy (for example <a href="https://bair.berkeley.edu/blog/2020/04/23/decisions/">Neural-Backed Decision Trees</a>).</p>
<div id="entropy" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Entropy</h2>
<p>Entropy measures the impurity of the given data. Low impurity leads to better classification and higher accuracy. The goal of Decision Trees is to split the data at each node with the highest gain of purity. The purity of the given dataset can be calculated with the <a href="https://en.wikipedia.org/wiki/Concave_function">concave</a> Entropy-Formula:
<span class="math display">\[
  E = -p \cdot log_2(p) - (1-p) \cdot log_2(1-p) 
\]</span></p>
<p>with <span class="math inline">\(p\)</span> as the probability of having no default in the credit default dataset. The Entropy increases to 1 if the dataset contains 50% of defaults and 50% of no default and decreases to 0 if the dataset contains only defaults or only no defaults. The python function is the following:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="decision-tree.html#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_entropy(df, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>):</span>
<span id="cb63-2"><a href="decision-tree.html#cb63-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(df)<span class="op">==</span><span class="dv">0</span>:</span>
<span id="cb63-3"><a href="decision-tree.html#cb63-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(<span class="dv">0</span>)</span>
<span id="cb63-4"><a href="decision-tree.html#cb63-4" aria-hidden="true" tabindex="-1"></a>  p <span class="op">=</span> np.<span class="bu">sum</span>(df[decision_on] <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(df)</span>
<span id="cb63-5"><a href="decision-tree.html#cb63-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> p <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> p <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb63-6"><a href="decision-tree.html#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(<span class="dv">0</span>)</span>
<span id="cb63-7"><a href="decision-tree.html#cb63-7" aria-hidden="true" tabindex="-1"></a>  result <span class="op">=</span> <span class="op">-</span>p <span class="op">*</span> ma.log(p,<span class="dv">2</span>) <span class="op">-</span> (<span class="dv">1</span><span class="op">-</span>p)<span class="op">*</span>ma.log(<span class="dv">1</span><span class="op">-</span>p,<span class="dv">2</span>)</span>
<span id="cb63-8"><a href="decision-tree.html#cb63-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> result</span></code></pre></div>
<p>Now can we calculate the initial Entropy of the credit default dataset as shown in the next code snippet:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="decision-tree.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb64-2"><a href="decision-tree.html#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math <span class="im">as</span> ma</span>
<span id="cb64-3"><a href="decision-tree.html#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb64-4"><a href="decision-tree.html#cb64-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-5"><a href="decision-tree.html#cb64-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&quot;example_data/credit_risk_dataset.csv&quot;</span>).fillna(<span class="dv">0</span>)</span>
<span id="cb64-6"><a href="decision-tree.html#cb64-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.replace({<span class="st">&quot;Y&quot;</span>: <span class="dv">1</span>, <span class="st">&quot;N&quot;</span>:<span class="dv">0</span>})</span>
<span id="cb64-7"><a href="decision-tree.html#cb64-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-8"><a href="decision-tree.html#cb64-8" aria-hidden="true" tabindex="-1"></a>entropy_of_data <span class="op">=</span> calc_entropy(df<span class="op">=</span>data)</span>
<span id="cb64-9"><a href="decision-tree.html#cb64-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Initial Inpurity/Entropy of data: &quot;</span>, entropy_of_data)</span></code></pre></div>
<pre><code>## Initial Inpurity/Entropy of data:  0.7568007498467375</code></pre>
<p>Sadly do we have the same problem with categorical data as the NN. We could transform categorical data to numerical as shown in the Credit Default chapter, but i want to drop these columns to make it easier to understand. Additional will we select only 4 columns plus the answer, to make it more interpretable and manageable.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="decision-tree.html#cb66-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.loc[:, [<span class="st">&quot;person_age&quot;</span>, <span class="st">&quot;loan_percent_income&quot;</span>, <span class="st">&quot;loan_int_rate&quot;</span>, <span class="st">&quot;cb_person_default_on_file&quot;</span> ,<span class="st">&quot;loan_status&quot;</span>]]</span></code></pre></div>
<p>Now do we need to create the nodes of the tree based on decisions that lead to the lowest Entropy. The resulting purity by splitting the data in 2 subsets by a condition of one column (value <span class="math inline">\(z\)</span>), can be calculated as:
<span class="math display">\[
  p_1(z) = \text{proportion of column-value} &gt; z \\
  p_2(z) = \text{proportion of no default and column-value} &gt; z \\
  p_3(z) = \text{proportion of no default and column-value} \leq z \\
  E_{split} = p_1(z) \cdot [-p_2(z) \cdot log_2(p_2(z)) - (1-p_2(z)) \cdot log_2(1-p_2(z))] \\
  +(1-p_1(z)) \cdot [-p_3(z) \cdot log_2(p_3(z)) - (1-p_3(z)) \cdot log_2(1-p_3(z))]
\]</span></p>
<p>and in python can we use the <code>calc_entropy</code> function to make it even simpler:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="decision-tree.html#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_splitted_entropy(df, col, val, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>):</span>
<span id="cb67-2"><a href="decision-tree.html#cb67-2" aria-hidden="true" tabindex="-1"></a>  w <span class="op">=</span> np.<span class="bu">sum</span>(df[col] <span class="op">&gt;</span> val)<span class="op">/</span><span class="bu">len</span>(df)</span>
<span id="cb67-3"><a href="decision-tree.html#cb67-3" aria-hidden="true" tabindex="-1"></a>  result <span class="op">=</span> w <span class="op">*</span> calc_entropy(df.loc[df[col] <span class="op">&gt;</span> val], decision_on) <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>w) <span class="op">*</span> calc_entropy(df.loc[df[col] <span class="op">&lt;=</span> val], decision_on)</span>
<span id="cb67-4"><a href="decision-tree.html#cb67-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> result</span></code></pre></div>
<p>For example can we split the dataset by column <code>loan_percent_income</code> and value <span class="math inline">\(z=0.3\)</span> to archive an decrease in Entropy:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="decision-tree.html#cb68-1" aria-hidden="true" tabindex="-1"></a>entropy_of_splitted_data <span class="op">=</span> calc_splitted_entropy(df<span class="op">=</span>data, col<span class="op">=</span><span class="st">&quot;loan_percent_income&quot;</span>, val<span class="op">=</span><span class="fl">0.3</span>, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>)</span>
<span id="cb68-2"><a href="decision-tree.html#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Splitted Inpurity/Entropy of data: &quot;</span>, entropy_of_splitted_data)</span></code></pre></div>
<pre><code>## Splitted Inpurity/Entropy of data:  0.648938734265563</code></pre>
<p>This split results in a decrease of <code>python round(entropy_of_data-entropy_of_splitted_data,5)</code> in the overall Entropy.</p>
</div>
<div id="constructing-the-tree" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Constructing the Tree</h2>
<p>First of all do we need to find the column and the value that results in the highest decrease of Entropy and splitt the dataset by it. Afterwards do we pass the resulting subsets into the same function (recursion). We will save the given conditions for the splitting. If the given subset contains less than <code>min_size</code> of rows or reached the <code>max_depth</code> it will turn into a leaf. We need to analyze the function properties to find the minimal value for the optimal splitting. The <code>calc_splitted_entropy</code> function is concave (“<a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">The Entropy is concave in the probability mass function</a>”). We can use this property to write a simple minimiza that checks if the next evaluation is smaller than the previous and steps along the input value. If the evaluation is bigger, it will change the direction and decrease the step distance. It repeats this process until the change in the evaluation is stagnating.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="decision-tree.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_minima(df, col, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>):</span>
<span id="cb70-2"><a href="decision-tree.html#cb70-2" aria-hidden="true" tabindex="-1"></a>  direction <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb70-3"><a href="decision-tree.html#cb70-3" aria-hidden="true" tabindex="-1"></a>  step <span class="op">=</span> (df[col].<span class="bu">max</span>()<span class="op">-</span>df[col].<span class="bu">min</span>()) <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb70-4"><a href="decision-tree.html#cb70-4" aria-hidden="true" tabindex="-1"></a>  val <span class="op">=</span> df[col].<span class="bu">min</span>() <span class="op">+</span> step</span>
<span id="cb70-5"><a href="decision-tree.html#cb70-5" aria-hidden="true" tabindex="-1"></a>  best_entropy <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb70-6"><a href="decision-tree.html#cb70-6" aria-hidden="true" tabindex="-1"></a>  stagnation <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb70-7"><a href="decision-tree.html#cb70-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb70-8"><a href="decision-tree.html#cb70-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">while</span> stagnation <span class="op">&lt;=</span> <span class="dv">15</span>:</span>
<span id="cb70-9"><a href="decision-tree.html#cb70-9" aria-hidden="true" tabindex="-1"></a>    temp <span class="op">=</span> calc_splitted_entropy(df, col, val)</span>
<span id="cb70-10"><a href="decision-tree.html#cb70-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> temp <span class="op">&gt;</span> best_entropy:</span>
<span id="cb70-11"><a href="decision-tree.html#cb70-11" aria-hidden="true" tabindex="-1"></a>      direction <span class="op">=</span> <span class="op">-</span>direction</span>
<span id="cb70-12"><a href="decision-tree.html#cb70-12" aria-hidden="true" tabindex="-1"></a>      step <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> step</span>
<span id="cb70-13"><a href="decision-tree.html#cb70-13" aria-hidden="true" tabindex="-1"></a>      stagnation <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb70-14"><a href="decision-tree.html#cb70-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="bu">round</span>(temp,round_at) <span class="op">&lt;</span> <span class="bu">round</span>(best_entropy,round_at):</span>
<span id="cb70-15"><a href="decision-tree.html#cb70-15" aria-hidden="true" tabindex="-1"></a>      stagnation <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb70-16"><a href="decision-tree.html#cb70-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb70-17"><a href="decision-tree.html#cb70-17" aria-hidden="true" tabindex="-1"></a>      stagnation <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb70-18"><a href="decision-tree.html#cb70-18" aria-hidden="true" tabindex="-1"></a>    best_entropy <span class="op">=</span> temp</span>
<span id="cb70-19"><a href="decision-tree.html#cb70-19" aria-hidden="true" tabindex="-1"></a>    val <span class="op">=</span> val <span class="op">+</span> direction <span class="op">*</span> step</span>
<span id="cb70-20"><a href="decision-tree.html#cb70-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb70-21"><a href="decision-tree.html#cb70-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> best_entropy, val</span></code></pre></div>
<p>This minimizer is written by my self and it only works for convex functions. I dont know if there do exist better approaches, but this one works.</p>
<p>Now do we need to find the best decrase in Entropy of all columns with the next function:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="decision-tree.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_best_col(df, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>):</span>
<span id="cb71-2"><a href="decision-tree.html#cb71-2" aria-hidden="true" tabindex="-1"></a>  cols <span class="op">=</span> <span class="bu">list</span>(df.columns[df.columns <span class="op">!=</span> decision_on])</span>
<span id="cb71-3"><a href="decision-tree.html#cb71-3" aria-hidden="true" tabindex="-1"></a>  entropys <span class="op">=</span> np.ones(<span class="bu">len</span>(cols))</span>
<span id="cb71-4"><a href="decision-tree.html#cb71-4" aria-hidden="true" tabindex="-1"></a>  vals <span class="op">=</span> np.ones(<span class="bu">len</span>(cols))</span>
<span id="cb71-5"><a href="decision-tree.html#cb71-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-6"><a href="decision-tree.html#cb71-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(cols)):</span>
<span id="cb71-7"><a href="decision-tree.html#cb71-7" aria-hidden="true" tabindex="-1"></a>    entropys[i], vals[i] <span class="op">=</span> find_minima(df, col<span class="op">=</span>cols[i], decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>)</span>
<span id="cb71-8"><a href="decision-tree.html#cb71-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-9"><a href="decision-tree.html#cb71-9" aria-hidden="true" tabindex="-1"></a>  best_i <span class="op">=</span> <span class="bu">int</span>(np.where(entropys <span class="op">==</span> <span class="bu">min</span>(entropys))[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb71-10"><a href="decision-tree.html#cb71-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> cols[best_i], entropys[best_i], vals[best_i]</span></code></pre></div>
<p>For example would the output for the initial dataste be:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="decision-tree.html#cb72-1" aria-hidden="true" tabindex="-1"></a>find_best_col(data)</span></code></pre></div>
<pre><code>## (&#39;loan_percent_income&#39;, 0.6564119496913492, 0.29990234374999997)</code></pre>
<p>Now its time to construct the tree and save all data that ends in a leaf:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="decision-tree.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_node_and_leafs(df, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>, path <span class="op">=</span> <span class="st">&quot;I&quot;</span>, condition <span class="op">=</span> <span class="st">&quot;&quot;</span>, min_size <span class="op">=</span> <span class="dv">1000</span>, max_depth <span class="op">=</span> <span class="dv">4</span>, leafs <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">&quot;path&quot;</span>, <span class="st">&quot;condition&quot;</span>, <span class="st">&quot;rows&quot;</span>, <span class="st">&quot;P_of_no_default&quot;</span>, <span class="st">&quot;entropy&quot;</span>])):</span>
<span id="cb74-2"><a href="decision-tree.html#cb74-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(df) <span class="op">&lt;</span> min_size <span class="kw">or</span> (path.count(<span class="st">&quot;-&quot;</span>)<span class="op">-</span><span class="dv">1</span>) <span class="op">&gt;=</span> max_depth <span class="kw">or</span> <span class="bu">len</span>(df.columns) <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb74-3"><a href="decision-tree.html#cb74-3" aria-hidden="true" tabindex="-1"></a>    leafs <span class="op">=</span> leafs.append({<span class="st">&quot;path&quot;</span>:path<span class="op">+</span><span class="st">&quot;}&quot;</span>, <span class="st">&quot;condition&quot;</span>:condition[<span class="dv">0</span>:(<span class="bu">len</span>(condition)<span class="op">-</span><span class="dv">5</span>)], <span class="st">&quot;rows&quot;</span>:<span class="bu">len</span>(df), <span class="st">&quot;P_of_no_default&quot;</span>:np.<span class="bu">sum</span>(df[decision_on] <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(df), <span class="st">&quot;entropy&quot;</span>:calc_entropy(df)}, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb74-4"><a href="decision-tree.html#cb74-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb74-5"><a href="decision-tree.html#cb74-5" aria-hidden="true" tabindex="-1"></a>    col, entropy, val <span class="op">=</span> find_best_col(df, decision_on, round_at)</span>
<span id="cb74-6"><a href="decision-tree.html#cb74-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;path:&quot;</span>, path, <span class="st">&quot;   entropy:&quot;</span>, entropy, <span class="st">&quot;  col:&quot;</span>, col, <span class="st">&quot;   val:&quot;</span>, val, <span class="st">&quot;  rows:&quot;</span>, <span class="bu">len</span>(df))</span>
<span id="cb74-7"><a href="decision-tree.html#cb74-7" aria-hidden="true" tabindex="-1"></a>    leafs <span class="op">=</span> make_node_and_leafs( df.loc[df[col] <span class="op">&gt;</span> val, df.columns <span class="op">!=</span> col], decision_on, round_at, path<span class="op">+</span><span class="st">&quot;-R&quot;</span>, condition<span class="op">+</span>col<span class="op">+</span><span class="st">&quot; &gt; &quot;</span><span class="op">+</span><span class="bu">str</span>(<span class="bu">float</span>(<span class="bu">round</span>(val,<span class="dv">5</span>)))<span class="op">+</span><span class="st">&quot; and &quot;</span>, min_size, max_depth, leafs)</span>
<span id="cb74-8"><a href="decision-tree.html#cb74-8" aria-hidden="true" tabindex="-1"></a>    leafs <span class="op">=</span> make_node_and_leafs( df.loc[df[col] <span class="op">&lt;=</span> val, df.columns <span class="op">!=</span> col], decision_on, round_at, path <span class="op">+</span> <span class="st">&quot;-L&quot;</span>, condition<span class="op">+</span>col<span class="op">+</span><span class="st">&quot; &lt;= &quot;</span><span class="op">+</span><span class="bu">str</span>(<span class="bu">float</span>(<span class="bu">round</span>(val,<span class="dv">5</span>)))<span class="op">+</span><span class="st">&quot; and &quot;</span>, min_size, max_depth, leafs)</span>
<span id="cb74-9"><a href="decision-tree.html#cb74-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(leafs)</span>
<span id="cb74-10"><a href="decision-tree.html#cb74-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-11"><a href="decision-tree.html#cb74-11" aria-hidden="true" tabindex="-1"></a>leafs <span class="op">=</span> make_node_and_leafs(df<span class="op">=</span>data, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>, min_size <span class="op">=</span> <span class="dv">1000</span>, max_depth <span class="op">=</span> <span class="dv">4</span>)</span>
<span id="cb74-12"><a href="decision-tree.html#cb74-12" aria-hidden="true" tabindex="-1"></a>leafs[<span class="st">&quot;entropy&quot;</span>] <span class="op">=</span> (leafs[<span class="st">&quot;entropy&quot;</span>]<span class="op">*</span>leafs[<span class="st">&quot;rows&quot;</span>])<span class="op">/</span><span class="bu">len</span>(data)</span>
<span id="cb74-13"><a href="decision-tree.html#cb74-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-14"><a href="decision-tree.html#cb74-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Entropy in data: &quot;</span>, calc_entropy(data))</span>
<span id="cb74-15"><a href="decision-tree.html#cb74-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Entropy in all leafs: &quot;</span>, np.<span class="bu">sum</span>(leafs[<span class="st">&quot;entropy&quot;</span>]))</span></code></pre></div>
<pre><code>## path: I    entropy: 0.6564119496913492   col: loan_percent_income    val: 0.29990234374999997   rows: 32581
## path: I-R    entropy: 0.9103981172376336   col: loan_int_rate    val: 14.01635546875   rows: 4285
## path: I-R-L    entropy: 0.9607335396537932   col: cb_person_default_on_file    val: 0.14999999999999947   rows: 3361
## path: I-R-L-L    entropy: 0.9648046914552115   col: person_age    val: 34.296875   rows: 2977
## path: I-L    entropy: 0.531844917392527   col: loan_int_rate    val: 14.280073242187505   rows: 28296
## path: I-L-R    entropy: 0.998669387657678   col: person_age    val: 22.3046875   rows: 4057
## path: I-L-R-R    entropy: 0.9992350724472542   col: cb_person_default_on_file    val: 0.14999999999999947   rows: 3488
## path: I-L-L    entropy: 0.44498607709157834   col: cb_person_default_on_file    val: 0.14999999999999947   rows: 24239
## path: I-L-L-R    entropy: 0.704963233218175   col: person_age    val: 33.9921875   rows: 2838
## path: I-L-L-L    entropy: 0.40973705382045866   col: person_age    val: 21.840624999999967   rows: 21401
## Entropy in data:  0.7568007498467375
## Entropy in all leafs:  0.574488597974446</code></pre>
<p>We can see that the Entropy of all leafs is significantly smaller than the initial Entropy.</p>
</div>
<div id="forcast-credit-defaults-with-dt" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Forcast Credit Defaults with DT</h2>
<p>We need to define a limit that splits all leafs in default and none default. Here do we choose the limit 0.65, that means that leafs with a probability of none default smaller than 65% will be classified as defaults. We can get this rows by using the conditions column in the <code>leafs</code>. The resulting analysis shows the quality of the forecast:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="decision-tree.html#cb76-1" aria-hidden="true" tabindex="-1"></a>data_temp <span class="op">=</span> data.copy()</span>
<span id="cb76-2"><a href="decision-tree.html#cb76-2" aria-hidden="true" tabindex="-1"></a>data_temp[<span class="st">&quot;ID&quot;</span>] <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(data_temp)))</span>
<span id="cb76-3"><a href="decision-tree.html#cb76-3" aria-hidden="true" tabindex="-1"></a>conditions <span class="op">=</span> <span class="st">&quot;(&quot;</span><span class="op">+</span> <span class="st">&quot;) | (&quot;</span>.join(<span class="bu">list</span>(leafs.loc[leafs[<span class="st">&quot;P_of_no_default&quot;</span>] <span class="op">&lt;</span> <span class="fl">0.65</span>, leafs.columns <span class="op">==</span> <span class="st">&quot;condition&quot;</span>][<span class="st">&quot;condition&quot;</span>].replace(<span class="st">&quot;and&quot;</span>,<span class="st">&quot;&amp;&quot;</span>)))<span class="op">+</span><span class="st">&quot;)&quot;</span></span>
<span id="cb76-4"><a href="decision-tree.html#cb76-4" aria-hidden="true" tabindex="-1"></a>data_temp <span class="op">=</span> data_temp.query(conditions)</span>
<span id="cb76-5"><a href="decision-tree.html#cb76-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.zeros(<span class="bu">len</span>(data))</span>
<span id="cb76-6"><a href="decision-tree.html#cb76-6" aria-hidden="true" tabindex="-1"></a>X[<span class="bu">list</span>(data_temp[<span class="st">&quot;ID&quot;</span>])] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb76-7"><a href="decision-tree.html#cb76-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-8"><a href="decision-tree.html#cb76-8" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> data.loc[:, data.columns <span class="op">==</span> <span class="st">&#39;loan_status&#39;</span>].to_numpy()[:,<span class="dv">0</span>]</span>
<span id="cb76-9"><a href="decision-tree.html#cb76-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-10"><a href="decision-tree.html#cb76-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Wrong answers of the decission tree: &quot;</span>,np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(Y<span class="op">-</span>X))<span class="op">/</span><span class="bu">len</span>(Y) <span class="op">*</span> <span class="dv">100</span>, <span class="st">&quot;%&quot;</span>)</span>
<span id="cb76-11"><a href="decision-tree.html#cb76-11" aria-hidden="true" tabindex="-1"></a>confusion_matrix(Y,X)</span></code></pre></div>
<pre><code>## Wrong answers of the decission tree:  17.94911144532089 %
## array([[21932,  3541],
##        [ 2307,  4801]], dtype=int64)</code></pre>
<p>We can compare the results to the previews created NN (with <code>hidden_layer_neurons = [4,4], alpha = 0.01, epochs = 500, batch_size = 2000</code>):</p>
</div>
<div id="extern-packages" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Extern Packages</h2>
<p>There do exist some packages to create DTs for example sklearn, but i wasnt able to get the data like in my own code:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="decision-tree.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree, export_graphviz, export_text</span>
<span id="cb78-2"><a href="decision-tree.html#cb78-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.drop(<span class="st">&#39;loan_status&#39;</span>,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb78-3"><a href="decision-tree.html#cb78-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">&#39;loan_status&#39;</span>]</span>
<span id="cb78-4"><a href="decision-tree.html#cb78-4" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier(criterion<span class="op">=</span><span class="st">&#39;entropy&#39;</span>,max_depth<span class="op">=</span><span class="dv">4</span>,min_samples_split<span class="op">=</span><span class="dv">1000</span>,min_samples_leaf<span class="op">=</span><span class="dv">200</span>,random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb78-5"><a href="decision-tree.html#cb78-5" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> clf.fit(X,y)</span>
<span id="cb78-6"><a href="decision-tree.html#cb78-6" aria-hidden="true" tabindex="-1"></a>pyplot.figure(figsize<span class="op">=</span>(<span class="dv">16</span>,<span class="dv">8</span>))</span>
<span id="cb78-7"><a href="decision-tree.html#cb78-7" aria-hidden="true" tabindex="-1"></a>plot_tree(clf, filled<span class="op">=</span><span class="va">True</span>, feature_names<span class="op">=</span>X.columns, proportion<span class="op">=</span><span class="va">False</span>, fontsize<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb78-8"><a href="decision-tree.html#cb78-8" aria-hidden="true" tabindex="-1"></a>pyplot.show()</span>
<span id="cb78-9"><a href="decision-tree.html#cb78-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-10"><a href="decision-tree.html#cb78-10" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> export_text(clf, feature_names<span class="op">=</span><span class="bu">list</span>(X.columns))</span>
<span id="cb78-11"><a href="decision-tree.html#cb78-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r)</span></code></pre></div>
<p><img src="gitbook-demo_files/figure-html/unnamed-chunk-37-22.png" width="1536" /></p>
<pre><code>## |--- loan_percent_income &lt;= 0.31
## |   |--- loan_int_rate &lt;= 14.03
## |   |   |--- cb_person_default_on_file &lt;= 0.50
## |   |   |   |--- loan_percent_income &lt;= 0.16
## |   |   |   |   |--- class: 0
## |   |   |   |--- loan_percent_income &gt;  0.16
## |   |   |   |   |--- class: 0
## |   |   |--- cb_person_default_on_file &gt;  0.50
## |   |   |   |--- loan_int_rate &lt;= 10.97
## |   |   |   |   |--- class: 0
## |   |   |   |--- loan_int_rate &gt;  10.97
## |   |   |   |   |--- class: 0
## |   |--- loan_int_rate &gt;  14.03
## |   |   |--- loan_int_rate &lt;= 15.28
## |   |   |   |--- loan_int_rate &lt;= 14.37
## |   |   |   |   |--- class: 0
## |   |   |   |--- loan_int_rate &gt;  14.37
## |   |   |   |   |--- class: 0
## |   |   |--- loan_int_rate &gt;  15.28
## |   |   |   |--- loan_int_rate &lt;= 16.85
## |   |   |   |   |--- class: 1
## |   |   |   |--- loan_int_rate &gt;  16.85
## |   |   |   |   |--- class: 1
## |--- loan_percent_income &gt;  0.31
## |   |--- loan_int_rate &lt;= 12.76
## |   |   |--- loan_int_rate &lt;= 9.97
## |   |   |   |--- loan_percent_income &lt;= 0.38
## |   |   |   |   |--- class: 1
## |   |   |   |--- loan_percent_income &gt;  0.38
## |   |   |   |   |--- class: 1
## |   |   |--- loan_int_rate &gt;  9.97
## |   |   |   |--- person_age &lt;= 22.50
## |   |   |   |   |--- class: 1
## |   |   |   |--- person_age &gt;  22.50
## |   |   |   |   |--- class: 1
## |   |--- loan_int_rate &gt;  12.76
## |   |   |--- loan_int_rate &lt;= 14.31
## |   |   |   |--- class: 1
## |   |   |--- loan_int_rate &gt;  14.31
## |   |   |   |--- class: 1</code></pre>
</div>
<div id="appendix-complete-code-5" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> Appendix (complete code)</h2>
<div class="sourceCode" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="decision-tree.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb80-2"><a href="decision-tree.html#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb80-3"><a href="decision-tree.html#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb80-4"><a href="decision-tree.html#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> pyplot</span>
<span id="cb80-5"><a href="decision-tree.html#cb80-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math <span class="im">as</span> ma</span>
<span id="cb80-6"><a href="decision-tree.html#cb80-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-7"><a href="decision-tree.html#cb80-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-8"><a href="decision-tree.html#cb80-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&quot;example_data/credit_risk_dataset.csv&quot;</span>).fillna(<span class="dv">0</span>)</span>
<span id="cb80-9"><a href="decision-tree.html#cb80-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.replace({<span class="st">&quot;Y&quot;</span>: <span class="dv">1</span>, <span class="st">&quot;N&quot;</span>:<span class="dv">0</span>})</span>
<span id="cb80-10"><a href="decision-tree.html#cb80-10" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.loc[:, [<span class="st">&quot;person_age&quot;</span>, <span class="st">&quot;loan_percent_income&quot;</span>, <span class="st">&quot;loan_int_rate&quot;</span>, <span class="st">&quot;cb_person_default_on_file&quot;</span> ,<span class="st">&quot;loan_status&quot;</span>]]</span>
<span id="cb80-11"><a href="decision-tree.html#cb80-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-12"><a href="decision-tree.html#cb80-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-13"><a href="decision-tree.html#cb80-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-14"><a href="decision-tree.html#cb80-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_entropy(df, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>):</span>
<span id="cb80-15"><a href="decision-tree.html#cb80-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(df)<span class="op">==</span><span class="dv">0</span>:</span>
<span id="cb80-16"><a href="decision-tree.html#cb80-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(<span class="dv">0</span>)</span>
<span id="cb80-17"><a href="decision-tree.html#cb80-17" aria-hidden="true" tabindex="-1"></a>  p <span class="op">=</span> np.<span class="bu">sum</span>(df[decision_on] <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(df)</span>
<span id="cb80-18"><a href="decision-tree.html#cb80-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> p <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> p <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb80-19"><a href="decision-tree.html#cb80-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(<span class="dv">0</span>)</span>
<span id="cb80-20"><a href="decision-tree.html#cb80-20" aria-hidden="true" tabindex="-1"></a>  result <span class="op">=</span> <span class="op">-</span>p <span class="op">*</span> ma.log(p,<span class="dv">2</span>) <span class="op">-</span> (<span class="dv">1</span><span class="op">-</span>p)<span class="op">*</span>ma.log(<span class="dv">1</span><span class="op">-</span>p,<span class="dv">2</span>)</span>
<span id="cb80-21"><a href="decision-tree.html#cb80-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> result</span>
<span id="cb80-22"><a href="decision-tree.html#cb80-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-23"><a href="decision-tree.html#cb80-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_splitted_entropy(df, col, val, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>):</span>
<span id="cb80-24"><a href="decision-tree.html#cb80-24" aria-hidden="true" tabindex="-1"></a>  w <span class="op">=</span> np.<span class="bu">sum</span>(df[col] <span class="op">&gt;</span> val)<span class="op">/</span><span class="bu">len</span>(df)</span>
<span id="cb80-25"><a href="decision-tree.html#cb80-25" aria-hidden="true" tabindex="-1"></a>  result <span class="op">=</span> w <span class="op">*</span> calc_entropy(df.loc[df[col] <span class="op">&gt;</span> val], decision_on) <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>w) <span class="op">*</span> calc_entropy(df.loc[df[col] <span class="op">&lt;=</span> val], decision_on)</span>
<span id="cb80-26"><a href="decision-tree.html#cb80-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> result</span>
<span id="cb80-27"><a href="decision-tree.html#cb80-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-28"><a href="decision-tree.html#cb80-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_minima(df, col, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>):</span>
<span id="cb80-29"><a href="decision-tree.html#cb80-29" aria-hidden="true" tabindex="-1"></a>  direction <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb80-30"><a href="decision-tree.html#cb80-30" aria-hidden="true" tabindex="-1"></a>  step <span class="op">=</span> (df[col].<span class="bu">max</span>()<span class="op">-</span>df[col].<span class="bu">min</span>()) <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb80-31"><a href="decision-tree.html#cb80-31" aria-hidden="true" tabindex="-1"></a>  val <span class="op">=</span> df[col].<span class="bu">min</span>() <span class="op">+</span> step</span>
<span id="cb80-32"><a href="decision-tree.html#cb80-32" aria-hidden="true" tabindex="-1"></a>  best_entropy <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb80-33"><a href="decision-tree.html#cb80-33" aria-hidden="true" tabindex="-1"></a>  stagnation <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb80-34"><a href="decision-tree.html#cb80-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-35"><a href="decision-tree.html#cb80-35" aria-hidden="true" tabindex="-1"></a>  <span class="cf">while</span> stagnation <span class="op">&lt;=</span> <span class="dv">15</span>:</span>
<span id="cb80-36"><a href="decision-tree.html#cb80-36" aria-hidden="true" tabindex="-1"></a>    temp <span class="op">=</span> calc_splitted_entropy(df, col, val)</span>
<span id="cb80-37"><a href="decision-tree.html#cb80-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> temp <span class="op">&gt;</span> best_entropy:</span>
<span id="cb80-38"><a href="decision-tree.html#cb80-38" aria-hidden="true" tabindex="-1"></a>      direction <span class="op">=</span> <span class="op">-</span>direction</span>
<span id="cb80-39"><a href="decision-tree.html#cb80-39" aria-hidden="true" tabindex="-1"></a>      step <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> step</span>
<span id="cb80-40"><a href="decision-tree.html#cb80-40" aria-hidden="true" tabindex="-1"></a>      stagnation <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb80-41"><a href="decision-tree.html#cb80-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="bu">round</span>(temp,round_at) <span class="op">&lt;</span> <span class="bu">round</span>(best_entropy,round_at):</span>
<span id="cb80-42"><a href="decision-tree.html#cb80-42" aria-hidden="true" tabindex="-1"></a>      stagnation <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb80-43"><a href="decision-tree.html#cb80-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb80-44"><a href="decision-tree.html#cb80-44" aria-hidden="true" tabindex="-1"></a>      stagnation <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb80-45"><a href="decision-tree.html#cb80-45" aria-hidden="true" tabindex="-1"></a>    best_entropy <span class="op">=</span> temp</span>
<span id="cb80-46"><a href="decision-tree.html#cb80-46" aria-hidden="true" tabindex="-1"></a>    val <span class="op">=</span> val <span class="op">+</span> direction <span class="op">*</span> step</span>
<span id="cb80-47"><a href="decision-tree.html#cb80-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb80-48"><a href="decision-tree.html#cb80-48" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> best_entropy, val</span>
<span id="cb80-49"><a href="decision-tree.html#cb80-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-50"><a href="decision-tree.html#cb80-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-51"><a href="decision-tree.html#cb80-51" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_best_col(df, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>):</span>
<span id="cb80-52"><a href="decision-tree.html#cb80-52" aria-hidden="true" tabindex="-1"></a>  cols <span class="op">=</span> <span class="bu">list</span>(df.columns[df.columns <span class="op">!=</span> decision_on])</span>
<span id="cb80-53"><a href="decision-tree.html#cb80-53" aria-hidden="true" tabindex="-1"></a>  entropys <span class="op">=</span> np.ones(<span class="bu">len</span>(cols))</span>
<span id="cb80-54"><a href="decision-tree.html#cb80-54" aria-hidden="true" tabindex="-1"></a>  vals <span class="op">=</span> np.ones(<span class="bu">len</span>(cols))</span>
<span id="cb80-55"><a href="decision-tree.html#cb80-55" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-56"><a href="decision-tree.html#cb80-56" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(cols)):</span>
<span id="cb80-57"><a href="decision-tree.html#cb80-57" aria-hidden="true" tabindex="-1"></a>    entropys[i], vals[i] <span class="op">=</span> find_minima(df, col<span class="op">=</span>cols[i], decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>)</span>
<span id="cb80-58"><a href="decision-tree.html#cb80-58" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-59"><a href="decision-tree.html#cb80-59" aria-hidden="true" tabindex="-1"></a>  best_i <span class="op">=</span> <span class="bu">int</span>(np.where(entropys <span class="op">==</span> <span class="bu">min</span>(entropys))[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb80-60"><a href="decision-tree.html#cb80-60" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> cols[best_i], entropys[best_i], vals[best_i]</span>
<span id="cb80-61"><a href="decision-tree.html#cb80-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-62"><a href="decision-tree.html#cb80-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-63"><a href="decision-tree.html#cb80-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-64"><a href="decision-tree.html#cb80-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-65"><a href="decision-tree.html#cb80-65" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_node_and_leafs(df, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>, path <span class="op">=</span> <span class="st">&quot;I&quot;</span>, condition <span class="op">=</span> <span class="st">&quot;&quot;</span>, min_size <span class="op">=</span> <span class="dv">1000</span>, max_depth <span class="op">=</span> <span class="dv">4</span>, leafs <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">&quot;path&quot;</span>, <span class="st">&quot;condition&quot;</span>, <span class="st">&quot;rows&quot;</span>, <span class="st">&quot;P_of_no_default&quot;</span>, <span class="st">&quot;entropy&quot;</span>])):</span>
<span id="cb80-66"><a href="decision-tree.html#cb80-66" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(df) <span class="op">&lt;</span> min_size <span class="kw">or</span> (path.count(<span class="st">&quot;-&quot;</span>)<span class="op">-</span><span class="dv">1</span>) <span class="op">&gt;=</span> max_depth <span class="kw">or</span> <span class="bu">len</span>(df.columns) <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb80-67"><a href="decision-tree.html#cb80-67" aria-hidden="true" tabindex="-1"></a>    leafs <span class="op">=</span> leafs.append({<span class="st">&quot;path&quot;</span>:path<span class="op">+</span><span class="st">&quot;}&quot;</span>, <span class="st">&quot;condition&quot;</span>:condition[<span class="dv">0</span>:(<span class="bu">len</span>(condition)<span class="op">-</span><span class="dv">5</span>)], <span class="st">&quot;rows&quot;</span>:<span class="bu">len</span>(df), <span class="st">&quot;P_of_no_default&quot;</span>:np.<span class="bu">sum</span>(df[decision_on] <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(df), <span class="st">&quot;entropy&quot;</span>:calc_entropy(df)}, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb80-68"><a href="decision-tree.html#cb80-68" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb80-69"><a href="decision-tree.html#cb80-69" aria-hidden="true" tabindex="-1"></a>    col, entropy, val <span class="op">=</span> find_best_col(df, decision_on, round_at)</span>
<span id="cb80-70"><a href="decision-tree.html#cb80-70" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;path:&quot;</span>, path, <span class="st">&quot;   entropy:&quot;</span>, entropy, <span class="st">&quot;  col:&quot;</span>, col, <span class="st">&quot;   val:&quot;</span>, val, <span class="st">&quot;  rows:&quot;</span>, <span class="bu">len</span>(df))</span>
<span id="cb80-71"><a href="decision-tree.html#cb80-71" aria-hidden="true" tabindex="-1"></a>    leafs <span class="op">=</span> make_node_and_leafs( df.loc[df[col] <span class="op">&gt;</span> val, df.columns <span class="op">!=</span> col], decision_on, round_at, path<span class="op">+</span><span class="st">&quot;-R&quot;</span>, condition<span class="op">+</span>col<span class="op">+</span><span class="st">&quot; &gt; &quot;</span><span class="op">+</span><span class="bu">str</span>(<span class="bu">float</span>(<span class="bu">round</span>(val,<span class="dv">5</span>)))<span class="op">+</span><span class="st">&quot; and &quot;</span>, min_size, max_depth, leafs)</span>
<span id="cb80-72"><a href="decision-tree.html#cb80-72" aria-hidden="true" tabindex="-1"></a>    leafs <span class="op">=</span> make_node_and_leafs( df.loc[df[col] <span class="op">&lt;=</span> val, df.columns <span class="op">!=</span> col], decision_on, round_at, path <span class="op">+</span> <span class="st">&quot;-L&quot;</span>, condition<span class="op">+</span>col<span class="op">+</span><span class="st">&quot; &lt;= &quot;</span><span class="op">+</span><span class="bu">str</span>(<span class="bu">float</span>(<span class="bu">round</span>(val,<span class="dv">5</span>)))<span class="op">+</span><span class="st">&quot; and &quot;</span>, min_size, max_depth, leafs)</span>
<span id="cb80-73"><a href="decision-tree.html#cb80-73" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(leafs)</span>
<span id="cb80-74"><a href="decision-tree.html#cb80-74" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-75"><a href="decision-tree.html#cb80-75" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-76"><a href="decision-tree.html#cb80-76" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-77"><a href="decision-tree.html#cb80-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-78"><a href="decision-tree.html#cb80-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-79"><a href="decision-tree.html#cb80-79" aria-hidden="true" tabindex="-1"></a>leafs <span class="op">=</span> make_node_and_leafs(df<span class="op">=</span>data, decision_on <span class="op">=</span> <span class="st">&quot;loan_status&quot;</span>, round_at <span class="op">=</span> <span class="dv">5</span>, min_size <span class="op">=</span> <span class="dv">1000</span>, max_depth <span class="op">=</span> <span class="dv">4</span>)</span>
<span id="cb80-80"><a href="decision-tree.html#cb80-80" aria-hidden="true" tabindex="-1"></a>leafs[<span class="st">&quot;entropy&quot;</span>] <span class="op">=</span> (leafs[<span class="st">&quot;entropy&quot;</span>]<span class="op">*</span>leafs[<span class="st">&quot;rows&quot;</span>])<span class="op">/</span><span class="bu">len</span>(data)</span>
<span id="cb80-81"><a href="decision-tree.html#cb80-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-82"><a href="decision-tree.html#cb80-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Entropy in data: &quot;</span>, calc_entropy(data))</span>
<span id="cb80-83"><a href="decision-tree.html#cb80-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Entropy in all leafs: &quot;</span>, np.<span class="bu">sum</span>(leafs[<span class="st">&quot;entropy&quot;</span>]))</span>
<span id="cb80-84"><a href="decision-tree.html#cb80-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-85"><a href="decision-tree.html#cb80-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-86"><a href="decision-tree.html#cb80-86" aria-hidden="true" tabindex="-1"></a>data_temp <span class="op">=</span> data.copy()</span>
<span id="cb80-87"><a href="decision-tree.html#cb80-87" aria-hidden="true" tabindex="-1"></a>data_temp[<span class="st">&quot;ID&quot;</span>] <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(data_temp)))</span>
<span id="cb80-88"><a href="decision-tree.html#cb80-88" aria-hidden="true" tabindex="-1"></a>conditions <span class="op">=</span> <span class="st">&quot;(&quot;</span><span class="op">+</span> <span class="st">&quot;) | (&quot;</span>.join(<span class="bu">list</span>(leafs.loc[leafs[<span class="st">&quot;P_of_no_default&quot;</span>] <span class="op">&lt;</span> <span class="fl">0.65</span>, leafs.columns <span class="op">==</span> <span class="st">&quot;condition&quot;</span>][<span class="st">&quot;condition&quot;</span>].replace(<span class="st">&quot;and&quot;</span>,<span class="st">&quot;&amp;&quot;</span>)))<span class="op">+</span><span class="st">&quot;)&quot;</span></span>
<span id="cb80-89"><a href="decision-tree.html#cb80-89" aria-hidden="true" tabindex="-1"></a>data_temp <span class="op">=</span> data_temp.query(conditions)</span>
<span id="cb80-90"><a href="decision-tree.html#cb80-90" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.zeros(<span class="bu">len</span>(data))</span>
<span id="cb80-91"><a href="decision-tree.html#cb80-91" aria-hidden="true" tabindex="-1"></a>X[<span class="bu">list</span>(data_temp[<span class="st">&quot;ID&quot;</span>])] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb80-92"><a href="decision-tree.html#cb80-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-93"><a href="decision-tree.html#cb80-93" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> data.loc[:, data.columns <span class="op">==</span> <span class="st">&#39;loan_status&#39;</span>].to_numpy()[:,<span class="dv">0</span>]</span>
<span id="cb80-94"><a href="decision-tree.html#cb80-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-95"><a href="decision-tree.html#cb80-95" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Wrong answers of the decission tree: &quot;</span>,np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(Y<span class="op">-</span>X))<span class="op">/</span><span class="bu">len</span>(Y) <span class="op">*</span> <span class="dv">100</span>, <span class="st">&quot;%&quot;</span>)</span>
<span id="cb80-96"><a href="decision-tree.html#cb80-96" aria-hidden="true" tabindex="-1"></a>confusion_matrix(Y,X)</span></code></pre></div>
<pre><code>## path: I    entropy: 0.6564119496913492   col: loan_percent_income    val: 0.29990234374999997   rows: 32581
## path: I-R    entropy: 0.9103981172376336   col: loan_int_rate    val: 14.01635546875   rows: 4285
## path: I-R-L    entropy: 0.9607335396537932   col: cb_person_default_on_file    val: 0.14999999999999947   rows: 3361
## path: I-R-L-L    entropy: 0.9648046914552115   col: person_age    val: 34.296875   rows: 2977
## path: I-L    entropy: 0.531844917392527   col: loan_int_rate    val: 14.280073242187505   rows: 28296
## path: I-L-R    entropy: 0.998669387657678   col: person_age    val: 22.3046875   rows: 4057
## path: I-L-R-R    entropy: 0.9992350724472542   col: cb_person_default_on_file    val: 0.14999999999999947   rows: 3488
## path: I-L-L    entropy: 0.44498607709157834   col: cb_person_default_on_file    val: 0.14999999999999947   rows: 24239
## path: I-L-L-R    entropy: 0.704963233218175   col: person_age    val: 33.9921875   rows: 2838
## path: I-L-L-L    entropy: 0.40973705382045866   col: person_age    val: 21.840624999999967   rows: 21401
## Entropy in data:  0.7568007498467375
## Entropy in all leafs:  0.574488597974446
## Wrong answers of the decission tree:  17.94911144532089 %
## array([[21932,  3541],
##        [ 2307,  4801]], dtype=int64)</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="class-mlp.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/cjvanlissa/gitbook-demo/edit/master/07_Decision_Tree.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["gitbook-demo.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
