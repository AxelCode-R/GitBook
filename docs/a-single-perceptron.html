<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 A single Perceptron | My First Steps in Neuronal Networks</title>
  <meta name="description" content="This GitBook should provide an slide insight into my own learning process of coding Neuronal Networks (NN). Additionaly its a good chance for me to learn how to write a GitBook." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 A single Perceptron | My First Steps in Neuronal Networks" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This GitBook should provide an slide insight into my own learning process of coding Neuronal Networks (NN). Additionaly its a good chance for me to learn how to write a GitBook." />
  <meta name="github-repo" content="https://github.com/AxelCode-R/GitBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 A single Perceptron | My First Steps in Neuronal Networks" />
  
  <meta name="twitter:description" content="This GitBook should provide an slide insight into my own learning process of coding Neuronal Networks (NN). Additionaly its a good chance for me to learn how to write a GitBook." />
  

<meta name="author" content="Axel Roth" />


<meta name="date" content="2021-11-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A GitBook for Teaching</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#me"><i class="fa fa-check"></i><b>1.1</b> Me</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#the-book"><i class="fa fa-check"></i><b>1.2</b> The Book</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#how-it-works"><i class="fa fa-check"></i><b>1.3</b> How it works</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="a-single-perceptron.html"><a href="a-single-perceptron.html"><i class="fa fa-check"></i><b>2</b> A single Perceptron</a>
<ul>
<li class="chapter" data-level="2.1" data-path="a-single-perceptron.html"><a href="a-single-perceptron.html#neural-network-basics"><i class="fa fa-check"></i><b>2.1</b> Neural Network Basics</a></li>
<li class="chapter" data-level="2.2" data-path="a-single-perceptron.html"><a href="a-single-perceptron.html#forward-pass"><i class="fa fa-check"></i><b>2.2</b> Forward pass</a></li>
<li class="chapter" data-level="2.3" data-path="a-single-perceptron.html"><a href="a-single-perceptron.html#backward-pass"><i class="fa fa-check"></i><b>2.3</b> backward pass</a></li>
<li class="chapter" data-level="2.4" data-path="a-single-perceptron.html"><a href="a-single-perceptron.html#single-perceptron"><i class="fa fa-check"></i><b>2.4</b> Single Perceptron</a></li>
<li class="chapter" data-level="2.5" data-path="a-single-perceptron.html"><a href="a-single-perceptron.html#appendix-full-code"><i class="fa fa-check"></i><b>2.5</b> Appendix (full code)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My First Steps in Neuronal Networks</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="a-single-perceptron" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> A single Perceptron</h1>
<p>In this chapter i will teach you how to code a single Perceptron in Python with more or the less only the numpy package. Numpy uses a vectorizible math structure in which you can easily calculate elementwise or do stuff like normal matrix multiplications with just a symbol (i always interprete Vectors as one dimensional matrixes!). At the most of the times its just translating math formulars into python code without changing its structure.<br />
First of all we are starting with the needed parameters, that are explained later:</p>
<p>Number of runs over the training data := <code>train_n</code><br />
Learning rate := <span class="math inline">\(\alpha =\)</span> <code>alpha</code><br />
and the activation function:<br />
<span class="math display">\[ 
step(s)= 
\begin{cases}
    1,&amp; s   \geq 0\\
    0,&amp; s &lt; 0
\end{cases}
\]</span>
This function is named the heavyside-function and should be the easiest activation function to start with.</p>
<p>The traings dataset is the following:
<span class="math display">\[
\left[
\begin{array}{cc|c}
x_i,_1 &amp; x_i,_2 &amp; y_i \\
\end{array}
\right]
\]</span>
<span class="math display">\[
\left[
\begin{array}{cc|c}
0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 1 \\
1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 1 \\
\end{array}
\right]
\]</span>
The provided traings dataset contains the <code>X_train</code> matrix with two inputs each scenario and the <code>Y_train</code> matrix with the correct output. If your looking exactly you can see that this is the OR-Gate. Later you will see why these type of problems are the only suitable things to do with a single neuron.<br />
For a wider use we will now change the <code>X_train</code> matrix a little bit by adding a column with ones on the left side of it. Now you will not understand but later you will. In short, its a dummy value to make it possible to shift the NN, so it can be better fitted. The new traings dataset looks like this:
<span class="math display">\[
\left[
\begin{array}{ccc|c}
x_i,_0 &amp; x_i,_1 &amp; x_i,_2 &amp; y_i \\
\end{array}
\right]
\]</span>
<span class="math display">\[
\left[
\begin{array}{ccc|c}
1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1 \\
\end{array}
\right]
\]</span></p>
<p>The needed python imports and default options are the following:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="a-single-perceptron.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="a-single-perceptron.html#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random <span class="im">as</span> ra</span>
<span id="cb2-3"><a href="a-single-perceptron.html#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-4"><a href="a-single-perceptron.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> pyplot</span>
<span id="cb2-5"><a href="a-single-perceptron.html#cb2-5" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.max_rows&#39;</span>, <span class="dv">500</span>)</span>
<span id="cb2-6"><a href="a-single-perceptron.html#cb2-6" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.max_columns&#39;</span>, <span class="dv">500</span>)</span>
<span id="cb2-7"><a href="a-single-perceptron.html#cb2-7" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.width&#39;</span>, <span class="dv">1000</span>)</span></code></pre></div>
<p>( Do you see more imports than only the numpy package? <a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">Yes</a> or No )</p>
<p>Now that we have all the needed parameters and settings, i can give you a quick overview of the algorithm.</p>
<div id="neural-network-basics" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Neural Network Basics</h2>
<p>In a NN we are having two basic parts, the forward pass and backward pass. In the forward pass we are calculating the weighted sum of each input with its weights of the layer to get the output. In the backward pass we are analysing the error to adjust the weights accordingly. This is it! This is all a NN will do. Now that you know, see you. I explained everything to you. Have a good life…<br />
Ahh no no ok we have a look deeper into it :)</p>
<p>Whats exactly is the forward pass in a single Perceptron? Its just the weighted sum like i said, so you have with the dimensions included for one scenario out of the traingdata the folowing:
<span class="math display">\[
  step(W^{(1,3)} \cdot x^{(3,1)}) = y^{(1,1)}
\]</span>
That is the normal approach to iterate over all scenarios in the trainingdata…<br />
But i think its not the right way to describe it because it gets very confusing to interpret it for all scenarios.</p>
<p>My next approach is to consider all scenarios in the trainingdata in one formular. If your data isnt that huge, its a much faster approach aswell. First of all we need to interpret the new dimensions of <span class="math inline">\(W\)</span> and <span class="math inline">\(X\)</span>.<br />
We have <span class="math inline">\(X\)</span> as:
<span class="math display">\[
  X = \left[
  \begin{array}{ccc}
  1 &amp; 0 &amp; 0 \\
  1 &amp; 0 &amp; 1 \\
  1 &amp; 1 &amp; 0 \\
  1 &amp; 1 &amp; 1 \\
  \end{array}
  \right]
\]</span>
each row describes the inputs for each neuron in the scenario <span class="math inline">\(i\)</span>.<br />
For the weights <span class="math inline">\(W\)</span> we have for example:
<span class="math display">\[
  W =\left[
  \begin{array}{c}
  0.1 \\ 
  0.2 \\ 
  0.3 \\
  \end{array}
  \right]
\]</span>
The new formular looks like this:
<span class="math display">\[
  step(X \cdot W) = Y
\]</span>
For example if you take a look at the <span class="math inline">\(i\)</span>-th row or scenario of <span class="math inline">\(X\)</span> you will see the following:
<span class="math display">\[
  Y_i,_0 = step([X_i,_0 \cdot W_0,_0 + X_i,_1 \cdot W_1,_0 + X_i,_2 \cdot W_2,_0])
\]</span>
and <span class="math inline">\(Y_i,_0\)</span> is the approximated output of the <span class="math inline">\(i\)</span>-th scenario. Now we can look at the NN and compare the formular with it:<br />
<img src="img/NN_01_v2.png" style="width:50.0%" alt="Made with the awesome chart website lucidecharts" />  </p>
<p>Yes it is the same, its the weighted sum of the inputs and evaluated with it the activationfunction to calculate the output of the scenario <span class="math inline">\(i\)</span>.</p>
</div>
<div id="forward-pass" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Forward pass</h2>
<p>Now we create the so called <code>forward()</code> function in python:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="a-single-perceptron.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward(X, W):</span>
<span id="cb3-2"><a href="a-single-perceptron.html#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>( step(X <span class="op">@</span> W) )</span></code></pre></div>
<p>(Numpy provides us with the <code>@</code> symbol to make a matrix multiplication and the <code>.T</code> to transpose)</p>
<p>Because we want to put one dimensional matrixes into the <code>step()</code> function we need to use numpy for the if-else statement:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="a-single-perceptron.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> step(s):</span>
<span id="cb4-2"><a href="a-single-perceptron.html#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>( np.where(s <span class="op">&gt;=</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>) )</span></code></pre></div>
<p>Here an small example for the forward pass:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="a-single-perceptron.html#cb5-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([</span>
<span id="cb5-2"><a href="a-single-perceptron.html#cb5-2" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>],</span>
<span id="cb5-3"><a href="a-single-perceptron.html#cb5-3" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>],</span>
<span id="cb5-4"><a href="a-single-perceptron.html#cb5-4" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>],</span>
<span id="cb5-5"><a href="a-single-perceptron.html#cb5-5" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>],</span>
<span id="cb5-6"><a href="a-single-perceptron.html#cb5-6" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb5-7"><a href="a-single-perceptron.html#cb5-7" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> np.array([</span>
<span id="cb5-8"><a href="a-single-perceptron.html#cb5-8" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.1</span>], </span>
<span id="cb5-9"><a href="a-single-perceptron.html#cb5-9" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.2</span>], </span>
<span id="cb5-10"><a href="a-single-perceptron.html#cb5-10" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.3</span>]</span>
<span id="cb5-11"><a href="a-single-perceptron.html#cb5-11" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb5-12"><a href="a-single-perceptron.html#cb5-12" aria-hidden="true" tabindex="-1"></a>Y_approx <span class="op">=</span> forward(X, W)</span>
<span id="cb5-13"><a href="a-single-perceptron.html#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Y_approx)</span></code></pre></div>
<pre><code>## [[1]
##  [1]
##  [1]
##  [1]]</code></pre>
<p>And these are all the generated outputs of our NN over all scenarios. Now we need to calculate the error and adjust the weights accordingly.</p>
</div>
<div id="backward-pass" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> backward pass</h2>
<p>To adjust the weights we need the Delta-Rule:
<span class="math display">\[
  W(t+1) = W(t) + \Delta W(t)
\]</span>
with
<span class="math display">\[
  \Delta W(t) = \alpha \cdot X^{T} \cdot (Y - \hat{Y})
\]</span>
and <span class="math inline">\(\hat{Y}\)</span> is the output of the NN.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="a-single-perceptron.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> backward(W, X, Y, alpha, Y_approx):</span>
<span id="cb7-2"><a href="a-single-perceptron.html#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(W <span class="op">+</span> alpha <span class="op">*</span> X.T <span class="op">@</span> (Y <span class="op">-</span> Y_approx))</span></code></pre></div>
<p>with the result of the forward pass and example data we have the following:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="a-single-perceptron.html#cb8-1" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.array([</span>
<span id="cb8-2"><a href="a-single-perceptron.html#cb8-2" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">0</span>],</span>
<span id="cb8-3"><a href="a-single-perceptron.html#cb8-3" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>],</span>
<span id="cb8-4"><a href="a-single-perceptron.html#cb8-4" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>],</span>
<span id="cb8-5"><a href="a-single-perceptron.html#cb8-5" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>]</span>
<span id="cb8-6"><a href="a-single-perceptron.html#cb8-6" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb8-7"><a href="a-single-perceptron.html#cb8-7" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb8-8"><a href="a-single-perceptron.html#cb8-8" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> backward(W, X, Y, alpha, Y_approx)</span></code></pre></div>
<p>and this is the new weight.</p>
</div>
<div id="single-perceptron" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Single Perceptron</h2>
<p>Now we want to do the same process multiple times, to train the NN:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="a-single-perceptron.html#cb9-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([</span>
<span id="cb9-2"><a href="a-single-perceptron.html#cb9-2" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>],</span>
<span id="cb9-3"><a href="a-single-perceptron.html#cb9-3" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>],</span>
<span id="cb9-4"><a href="a-single-perceptron.html#cb9-4" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>],</span>
<span id="cb9-5"><a href="a-single-perceptron.html#cb9-5" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>],</span>
<span id="cb9-6"><a href="a-single-perceptron.html#cb9-6" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb9-7"><a href="a-single-perceptron.html#cb9-7" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.array([</span>
<span id="cb9-8"><a href="a-single-perceptron.html#cb9-8" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">0</span>],</span>
<span id="cb9-9"><a href="a-single-perceptron.html#cb9-9" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>],</span>
<span id="cb9-10"><a href="a-single-perceptron.html#cb9-10" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>],</span>
<span id="cb9-11"><a href="a-single-perceptron.html#cb9-11" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>]</span>
<span id="cb9-12"><a href="a-single-perceptron.html#cb9-12" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb9-13"><a href="a-single-perceptron.html#cb9-13" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> np.array([</span>
<span id="cb9-14"><a href="a-single-perceptron.html#cb9-14" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.1</span>], </span>
<span id="cb9-15"><a href="a-single-perceptron.html#cb9-15" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.2</span>], </span>
<span id="cb9-16"><a href="a-single-perceptron.html#cb9-16" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.3</span>]</span>
<span id="cb9-17"><a href="a-single-perceptron.html#cb9-17" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb9-18"><a href="a-single-perceptron.html#cb9-18" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb9-19"><a href="a-single-perceptron.html#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="a-single-perceptron.html#cb9-20" aria-hidden="true" tabindex="-1"></a>errors <span class="op">=</span> []</span>
<span id="cb9-21"><a href="a-single-perceptron.html#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb9-22"><a href="a-single-perceptron.html#cb9-22" aria-hidden="true" tabindex="-1"></a>  Y_approx <span class="op">=</span> forward(X, W)</span>
<span id="cb9-23"><a href="a-single-perceptron.html#cb9-23" aria-hidden="true" tabindex="-1"></a>  errors.append(Y <span class="op">-</span> Y_approx)</span>
<span id="cb9-24"><a href="a-single-perceptron.html#cb9-24" aria-hidden="true" tabindex="-1"></a>  W <span class="op">=</span> backward(W, X, Y, alpha, Y_approx)</span></code></pre></div>
<p>The KNN is trained now. Now we want to look at the error. We want to measure the mean-square-error with the following formula:
<span class="math display">\[
  Error_i = \frac{1}{2} \cdot \sum(Y-\hat{Y})^2
\]</span>
or as python code:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="a-single-perceptron.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mean_square_error(error):</span>
<span id="cb10-2"><a href="a-single-perceptron.html#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>( <span class="fl">0.5</span> <span class="op">*</span> np.<span class="bu">sum</span>(error <span class="op">**</span> <span class="dv">2</span>) )</span></code></pre></div>
<p>Now we need to calculate the mean-square-error for each element in the list <code>errors</code> which is made with <code>map</code>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="a-single-perceptron.html#cb11-1" aria-hidden="true" tabindex="-1"></a>mean_square_errors <span class="op">=</span> np.array(<span class="bu">list</span>(<span class="bu">map</span>(mean_square_error, errors)))</span></code></pre></div>
<p>To plot, im using the following function:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="a-single-perceptron.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_error(errors, title):</span>
<span id="cb12-2"><a href="a-single-perceptron.html#cb12-2" aria-hidden="true" tabindex="-1"></a>  x <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(errors)))</span>
<span id="cb12-3"><a href="a-single-perceptron.html#cb12-3" aria-hidden="true" tabindex="-1"></a>  y <span class="op">=</span> np.array(errors)</span>
<span id="cb12-4"><a href="a-single-perceptron.html#cb12-4" aria-hidden="true" tabindex="-1"></a>  pyplot.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">6</span>))</span>
<span id="cb12-5"><a href="a-single-perceptron.html#cb12-5" aria-hidden="true" tabindex="-1"></a>  pyplot.plot(x, y, <span class="st">&quot;g&quot;</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-6"><a href="a-single-perceptron.html#cb12-6" aria-hidden="true" tabindex="-1"></a>  pyplot.xlabel(<span class="st">&quot;Iterations&quot;</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb12-7"><a href="a-single-perceptron.html#cb12-7" aria-hidden="true" tabindex="-1"></a>  pyplot.ylabel(<span class="st">&quot;Mean Square Error&quot;</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb12-8"><a href="a-single-perceptron.html#cb12-8" aria-hidden="true" tabindex="-1"></a>  pyplot.title(title)</span>
<span id="cb12-9"><a href="a-single-perceptron.html#cb12-9" aria-hidden="true" tabindex="-1"></a>  pyplot.ylim(<span class="op">-</span><span class="fl">0.01</span>,<span class="bu">max</span>(errors)<span class="op">*</span><span class="fl">1.2</span>)</span>
<span id="cb12-10"><a href="a-single-perceptron.html#cb12-10" aria-hidden="true" tabindex="-1"></a>  pyplot.show()</span>
<span id="cb12-11"><a href="a-single-perceptron.html#cb12-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-12"><a href="a-single-perceptron.html#cb12-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-13"><a href="a-single-perceptron.html#cb12-13" aria-hidden="true" tabindex="-1"></a>plot_error(mean_square_errors, <span class="st">&quot;Mean-Square-Errors of a single Perceptron&quot;</span>)</span></code></pre></div>
<p><img src="gitbook-demo_files/figure-html/unnamed-chunk-11-1.png" width="576" /></p>
<p>If you survived until now, you have learned how you can programm a single Perceptron!</p>
</div>
<div id="appendix-full-code" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Appendix (full code)</h2>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="a-single-perceptron.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-2"><a href="a-single-perceptron.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random <span class="im">as</span> ra</span>
<span id="cb13-3"><a href="a-single-perceptron.html#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-4"><a href="a-single-perceptron.html#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> pyplot</span>
<span id="cb13-5"><a href="a-single-perceptron.html#cb13-5" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.max_rows&#39;</span>, <span class="dv">500</span>)</span>
<span id="cb13-6"><a href="a-single-perceptron.html#cb13-6" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.max_columns&#39;</span>, <span class="dv">500</span>)</span>
<span id="cb13-7"><a href="a-single-perceptron.html#cb13-7" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.width&#39;</span>, <span class="dv">1000</span>)</span>
<span id="cb13-8"><a href="a-single-perceptron.html#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="a-single-perceptron.html#cb13-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([</span>
<span id="cb13-10"><a href="a-single-perceptron.html#cb13-10" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>],</span>
<span id="cb13-11"><a href="a-single-perceptron.html#cb13-11" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>],</span>
<span id="cb13-12"><a href="a-single-perceptron.html#cb13-12" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>],</span>
<span id="cb13-13"><a href="a-single-perceptron.html#cb13-13" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>],</span>
<span id="cb13-14"><a href="a-single-perceptron.html#cb13-14" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb13-15"><a href="a-single-perceptron.html#cb13-15" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.array([</span>
<span id="cb13-16"><a href="a-single-perceptron.html#cb13-16" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">0</span>],</span>
<span id="cb13-17"><a href="a-single-perceptron.html#cb13-17" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>],</span>
<span id="cb13-18"><a href="a-single-perceptron.html#cb13-18" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>],</span>
<span id="cb13-19"><a href="a-single-perceptron.html#cb13-19" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>]</span>
<span id="cb13-20"><a href="a-single-perceptron.html#cb13-20" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb13-21"><a href="a-single-perceptron.html#cb13-21" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> np.array([</span>
<span id="cb13-22"><a href="a-single-perceptron.html#cb13-22" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.1</span>], </span>
<span id="cb13-23"><a href="a-single-perceptron.html#cb13-23" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.2</span>], </span>
<span id="cb13-24"><a href="a-single-perceptron.html#cb13-24" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.3</span>]</span>
<span id="cb13-25"><a href="a-single-perceptron.html#cb13-25" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb13-26"><a href="a-single-perceptron.html#cb13-26" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb13-27"><a href="a-single-perceptron.html#cb13-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="a-single-perceptron.html#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="a-single-perceptron.html#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> step(s):</span>
<span id="cb13-30"><a href="a-single-perceptron.html#cb13-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>( np.where(s <span class="op">&gt;=</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>) )</span>
<span id="cb13-31"><a href="a-single-perceptron.html#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="a-single-perceptron.html#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="a-single-perceptron.html#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward(X, W):</span>
<span id="cb13-34"><a href="a-single-perceptron.html#cb13-34" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>( step(X <span class="op">@</span> W) )</span>
<span id="cb13-35"><a href="a-single-perceptron.html#cb13-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-36"><a href="a-single-perceptron.html#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> backward(W, X, Y, alpha, Y_approx):</span>
<span id="cb13-37"><a href="a-single-perceptron.html#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(W <span class="op">+</span> alpha <span class="op">*</span> X.T <span class="op">@</span> (Y <span class="op">-</span> Y_approx))</span>
<span id="cb13-38"><a href="a-single-perceptron.html#cb13-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-39"><a href="a-single-perceptron.html#cb13-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-40"><a href="a-single-perceptron.html#cb13-40" aria-hidden="true" tabindex="-1"></a>errors <span class="op">=</span> []</span>
<span id="cb13-41"><a href="a-single-perceptron.html#cb13-41" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb13-42"><a href="a-single-perceptron.html#cb13-42" aria-hidden="true" tabindex="-1"></a>  Y_approx <span class="op">=</span> forward(X, W)</span>
<span id="cb13-43"><a href="a-single-perceptron.html#cb13-43" aria-hidden="true" tabindex="-1"></a>  errors.append(Y <span class="op">-</span> Y_approx)</span>
<span id="cb13-44"><a href="a-single-perceptron.html#cb13-44" aria-hidden="true" tabindex="-1"></a>  W <span class="op">=</span> backward(W, X, Y, alpha, Y_approx)</span>
<span id="cb13-45"><a href="a-single-perceptron.html#cb13-45" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-46"><a href="a-single-perceptron.html#cb13-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-47"><a href="a-single-perceptron.html#cb13-47" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-48"><a href="a-single-perceptron.html#cb13-48" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mean_square_error(error):</span>
<span id="cb13-49"><a href="a-single-perceptron.html#cb13-49" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>( <span class="fl">0.5</span> <span class="op">*</span> np.<span class="bu">sum</span>(error <span class="op">**</span> <span class="dv">2</span>) )</span>
<span id="cb13-50"><a href="a-single-perceptron.html#cb13-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-51"><a href="a-single-perceptron.html#cb13-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-52"><a href="a-single-perceptron.html#cb13-52" aria-hidden="true" tabindex="-1"></a>mean_square_errors <span class="op">=</span> np.array(<span class="bu">list</span>(<span class="bu">map</span>(mean_square_error, errors)))</span>
<span id="cb13-53"><a href="a-single-perceptron.html#cb13-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-54"><a href="a-single-perceptron.html#cb13-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-55"><a href="a-single-perceptron.html#cb13-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_error(errors, title):</span>
<span id="cb13-56"><a href="a-single-perceptron.html#cb13-56" aria-hidden="true" tabindex="-1"></a>  x <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(errors)))</span>
<span id="cb13-57"><a href="a-single-perceptron.html#cb13-57" aria-hidden="true" tabindex="-1"></a>  y <span class="op">=</span> np.array(errors)</span>
<span id="cb13-58"><a href="a-single-perceptron.html#cb13-58" aria-hidden="true" tabindex="-1"></a>  pyplot.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">6</span>))</span>
<span id="cb13-59"><a href="a-single-perceptron.html#cb13-59" aria-hidden="true" tabindex="-1"></a>  pyplot.plot(x, y, <span class="st">&quot;g&quot;</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-60"><a href="a-single-perceptron.html#cb13-60" aria-hidden="true" tabindex="-1"></a>  pyplot.xlabel(<span class="st">&quot;Iterations&quot;</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb13-61"><a href="a-single-perceptron.html#cb13-61" aria-hidden="true" tabindex="-1"></a>  pyplot.ylabel(<span class="st">&quot;Mean Square Error&quot;</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb13-62"><a href="a-single-perceptron.html#cb13-62" aria-hidden="true" tabindex="-1"></a>  pyplot.title(title)</span>
<span id="cb13-63"><a href="a-single-perceptron.html#cb13-63" aria-hidden="true" tabindex="-1"></a>  pyplot.ylim(<span class="op">-</span><span class="fl">0.01</span>,<span class="bu">max</span>(errors)<span class="op">*</span><span class="fl">1.2</span>)</span>
<span id="cb13-64"><a href="a-single-perceptron.html#cb13-64" aria-hidden="true" tabindex="-1"></a>  pyplot.xticks(x)</span>
<span id="cb13-65"><a href="a-single-perceptron.html#cb13-65" aria-hidden="true" tabindex="-1"></a>  pyplot.show()</span>
<span id="cb13-66"><a href="a-single-perceptron.html#cb13-66" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-67"><a href="a-single-perceptron.html#cb13-67" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-68"><a href="a-single-perceptron.html#cb13-68" aria-hidden="true" tabindex="-1"></a>plot_error(mean_square_errors, <span class="st">&quot;Mean-Square-Errors of a single Perceptron&quot;</span>)</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/cjvanlissa/gitbook-demo/edit/master/00_Introduction.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["gitbook-demo.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
